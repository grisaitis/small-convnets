{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial: CIFAR-10 classification\n",
    "\n",
    "Source: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "/Users/william/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "\n",
    "# data loader\n",
    "batch_size = 4\n",
    "test_batch_size = 4\n",
    "\n",
    "# trainer\n",
    "epochs = 2\n",
    "\n",
    "# optimizer\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "# no_cuda = True  # not used\n",
    "seed = 1\n",
    "log_interval = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11237a210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane   dog  deer  deer\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "sgd_optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, epoch, log_interval):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == (log_interval - 1):\n",
    "            print('Train Epoch: {} [{:05d}/{:05d} ({:02.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                (batch_idx + 1) * len(inputs),\n",
    "                len(data_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(data_loader),\n",
    "                running_loss / log_interval))\n",
    "            running_loss = 0.0\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            losses = criterion(outputs, labels)\n",
    "            test_loss += torch.sum(losses)\n",
    "            pred = outputs.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    n_cases = len(data_loader.dataset)\n",
    "    print(\"n_cases:\", n_cases)\n",
    "    test_loss /= n_cases\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss,\n",
    "        correct,\n",
    "        len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [08000/50000 (16%)]\tLoss: 8.050952\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 6.900259\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 6.661740\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 6.423126\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 6.331477\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 6.200371\n",
      "n_cases: 10000\n",
      "\n",
      "Test set: Average loss: 1.5439, Accuracy: 4440/10000 (44%)\n",
      "\n",
      "Train Epoch: 2 [08000/50000 (16%)]\tLoss: 6.081241\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 6.019436\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 5.985378\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 5.912212\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 6.033348\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 5.985319\n",
      "n_cases: 10000\n",
      "\n",
      "Test set: Average loss: 1.4600, Accuracy: 4784/10000 (48%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test(net, test_loader, criterion)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(net, train_loader, sgd_optimizer, criterion, epoch, log_interval)\n",
    "    test(net, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n",
    "Original:\n",
    "\n",
    "[1,  2000] loss: 2.186\n",
    "[1,  4000] loss: 1.841\n",
    "[1,  6000] loss: 1.673\n",
    "[1,  8000] loss: 1.563\n",
    "[1, 10000] loss: 1.511\n",
    "[1, 12000] loss: 1.440\n",
    "[2,  2000] loss: 1.399\n",
    "[2,  4000] loss: 1.353\n",
    "[2,  6000] loss: 1.329\n",
    "[2,  8000] loss: 1.300\n",
    "[2, 10000] loss: 1.292\n",
    "[2, 12000] loss: 1.289\n",
    "Finished Training''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
