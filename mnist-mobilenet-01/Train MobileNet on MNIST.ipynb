{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "- PyTorch MNIST example - https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "- pytorch cifar10 code - https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "- LeNet for CIFAR-10 - https://github.com/kuangliu/pytorch-cifar/blob/master/models/lenet.py\n",
    "\n",
    "### My notes\n",
    "- My Google Doc - https://docs.google.com/document/d/1nPvFULraomLmBp4IuNVe51YXV1DQsSzgQWtuaZhbkjo/edit\n",
    "- Trello - https://trello.com/b/ycCGjD3A/mobile-dl\n",
    "- Using webcam - https://docs.google.com/document/d/17BVx5yioNaV11mip4U9gRAO7wLIJf-aOpIITJPjqeks/edit#\n",
    "- Installing pytorch - https://docs.google.com/document/d/1NfLbuhoOxonzS9FEeooyqpB90-62Gat-uZ2DOTaWRdg/edit#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "/Users/william/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenet.py\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, epochs=10, log_interval=10, lr=0.01, momentum=0.5, no_cuda=False, seed=1, test_batch_size=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(args=[\"--epochs=10\"])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ffe81d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): Block(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): Block(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.5\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # to do: needed?\n",
    "        optimizer.zero_grad()  # what does this do? zero-out any previous gradient info?\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            digits = int(math.log10(len(train_loader.dataset))) + 1\n",
    "            print('Train Epoch: {} [{:05d}/{:05d} ({:02.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/60000 (00%)]\tLoss: 0.043977\n",
      "Train Epoch: 1 [00640/60000 (01%)]\tLoss: -0.985935\n",
      "Train Epoch: 1 [01280/60000 (02%)]\tLoss: -2.220369\n",
      "Train Epoch: 1 [01920/60000 (03%)]\tLoss: -3.390295\n",
      "Train Epoch: 1 [02560/60000 (04%)]\tLoss: -4.682779\n",
      "Train Epoch: 1 [03200/60000 (05%)]\tLoss: -6.117853\n",
      "Train Epoch: 1 [03840/60000 (06%)]\tLoss: -7.380120\n",
      "Train Epoch: 1 [04480/60000 (07%)]\tLoss: -9.039014\n",
      "Train Epoch: 1 [05120/60000 (09%)]\tLoss: -11.072659\n",
      "Train Epoch: 1 [05760/60000 (10%)]\tLoss: -14.599996\n",
      "Train Epoch: 1 [06400/60000 (11%)]\tLoss: -20.396000\n",
      "Train Epoch: 1 [07040/60000 (12%)]\tLoss: -24.732157\n",
      "Train Epoch: 1 [07680/60000 (13%)]\tLoss: -28.159323\n",
      "Train Epoch: 1 [08320/60000 (14%)]\tLoss: -25.959940\n",
      "Train Epoch: 1 [08960/60000 (15%)]\tLoss: -43.081261\n",
      "Train Epoch: 1 [09600/60000 (16%)]\tLoss: -53.836346\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: -59.079845\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: -70.458763\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: -58.140465\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: -70.274185\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -98.300842\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: -118.269028\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: -128.515915\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: -120.839645\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: -176.823822\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: -169.617294\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: -223.969971\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: -231.840988\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: -275.428223\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: -290.107971\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -314.111450\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: -313.870483\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: -520.897400\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: -449.049316\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: -236.949097\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: -635.193665\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: -616.791443\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: -811.674988\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: -873.442810\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: -1073.479858\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -1097.285034\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: -1308.831787\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: -1645.650269\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: -1604.413574\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: -1966.817505\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: -2193.665039\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: -2270.594727\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: -2342.496582\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: -2918.379395\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: -3335.841309\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -3970.723633\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: -3955.093506\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: -4739.802246\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: -5786.830566\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: -6806.113770\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: -6812.386719\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: -8746.600586\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: -8956.749023\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: -11819.841797\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: -12602.508789\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: -13108.975586\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: -13977.534180\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: -17350.410156\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: -18707.507812\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: -18758.787109\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: -22883.753906\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: -30981.902344\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: -27952.349609\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: -23847.890625\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: -35714.707031\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: -38850.535156\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: -55217.222656\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: -54055.679688\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: -64015.445312\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: -83898.507812\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: -76460.109375\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: -81247.695312\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: -125930.625000\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: -124155.054688\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: -149582.390625\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -57272.789062\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: -50212.406250\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: -52717.230469\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: -70386.093750\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: -170262.875000\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: -159468.218750\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: -194063.890625\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: -216205.125000\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: -275163.031250\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: -327847.375000\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: -376189.687500\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: -280916.375000\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: -303436.656250\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: -453597.718750\n",
      "\n",
      "Test set: Average loss: -2668871346349827.5000, Accuracy: 1406/10000 (14%)\n",
      "\n",
      "Train Epoch: 2 [00000/60000 (00%)]\tLoss: -501508.687500\n",
      "Train Epoch: 2 [00640/60000 (01%)]\tLoss: -680030.187500\n",
      "Train Epoch: 2 [01280/60000 (02%)]\tLoss: -542492.062500\n",
      "Train Epoch: 2 [01920/60000 (03%)]\tLoss: -839088.750000\n",
      "Train Epoch: 2 [02560/60000 (04%)]\tLoss: -925809.812500\n",
      "Train Epoch: 2 [03200/60000 (05%)]\tLoss: -897640.375000\n",
      "Train Epoch: 2 [03840/60000 (06%)]\tLoss: -1172929.000000\n",
      "Train Epoch: 2 [04480/60000 (07%)]\tLoss: -1155631.625000\n",
      "Train Epoch: 2 [05120/60000 (09%)]\tLoss: -1567627.875000\n",
      "Train Epoch: 2 [05760/60000 (10%)]\tLoss: -1578979.875000\n",
      "Train Epoch: 2 [06400/60000 (11%)]\tLoss: -1545364.125000\n",
      "Train Epoch: 2 [07040/60000 (12%)]\tLoss: -2314437.500000\n",
      "Train Epoch: 2 [07680/60000 (13%)]\tLoss: -2262285.000000\n",
      "Train Epoch: 2 [08320/60000 (14%)]\tLoss: -2776495.500000\n",
      "Train Epoch: 2 [08960/60000 (15%)]\tLoss: -3053727.000000\n",
      "Train Epoch: 2 [09600/60000 (16%)]\tLoss: -2189764.750000\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: -3803136.500000\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: -4083287.000000\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: -4297726.500000\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: -2096908.625000\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: -3261759.000000\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: -3973901.500000\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: -8419500.000000\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: -7944826.000000\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: -7754224.500000\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: -10424304.000000\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: -13911240.000000\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: -9889287.000000\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: -15929438.000000\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: -16258494.000000\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: -20640224.000000\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: -24873228.000000\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: -22709952.000000\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: -25748760.000000\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: -26792412.000000\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: -29234044.000000\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: -40765936.000000\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: -38803632.000000\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: -46925600.000000\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: -48480624.000000\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -68781096.000000\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: -70685336.000000\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: -81103800.000000\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: -74424784.000000\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: -89670648.000000\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: -95004112.000000\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: -112658640.000000\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: -135989248.000000\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: -148138144.000000\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: -220615584.000000\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: -202160640.000000\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: -223170752.000000\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: -278415968.000000\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: -338544736.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: -354680608.000000\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: -269680544.000000\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: -495418528.000000\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: -473967328.000000\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: -534678880.000000\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: -731943168.000000\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: -418707936.000000\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: -540441856.000000\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: -672028224.000000\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: -616283968.000000\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: -757077952.000000\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: -935214016.000000\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: -1009635968.000000\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: -1119472768.000000\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: -1253954560.000000\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: -1461774848.000000\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: -1626591232.000000\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: -1891915904.000000\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: -1896194048.000000\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: -2308154624.000000\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: -2508813824.000000\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: -2873061632.000000\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: -3191490304.000000\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: -3506649600.000000\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: -4026432256.000000\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: -4539155456.000000\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -5098326528.000000\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: -5846525440.000000\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: -6560710144.000000\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: -7329326592.000000\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: -8213469184.000000\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: -9290134528.000000\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: -10035178496.000000\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: -11472386048.000000\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: -13014550528.000000\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: -14341797888.000000\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: -16388093952.000000\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: -18993670144.000000\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: -21284710400.000000\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: -23502415872.000000\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 3 [00000/60000 (00%)]\tLoss: -26701895680.000000\n",
      "Train Epoch: 3 [00640/60000 (01%)]\tLoss: -28915949568.000000\n",
      "Train Epoch: 3 [01280/60000 (02%)]\tLoss: -33118939136.000000\n",
      "Train Epoch: 3 [01920/60000 (03%)]\tLoss: -36145053696.000000\n",
      "Train Epoch: 3 [02560/60000 (04%)]\tLoss: -40721293312.000000\n",
      "Train Epoch: 3 [03200/60000 (05%)]\tLoss: -46222938112.000000\n",
      "Train Epoch: 3 [03840/60000 (06%)]\tLoss: -52415447040.000000\n",
      "Train Epoch: 3 [04480/60000 (07%)]\tLoss: -57564479488.000000\n",
      "Train Epoch: 3 [05120/60000 (09%)]\tLoss: -65446043648.000000\n",
      "Train Epoch: 3 [05760/60000 (10%)]\tLoss: -73116598272.000000\n",
      "Train Epoch: 3 [06400/60000 (11%)]\tLoss: -83078750208.000000\n",
      "Train Epoch: 3 [07040/60000 (12%)]\tLoss: -93081518080.000000\n",
      "Train Epoch: 3 [07680/60000 (13%)]\tLoss: -104925528064.000000\n",
      "Train Epoch: 3 [08320/60000 (14%)]\tLoss: -119949959168.000000\n",
      "Train Epoch: 3 [08960/60000 (15%)]\tLoss: -133367521280.000000\n",
      "Train Epoch: 3 [09600/60000 (16%)]\tLoss: -151168876544.000000\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: -167022034944.000000\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: -190236672000.000000\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: -212960100352.000000\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: -241873240064.000000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: -270594424832.000000\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: -305507729408.000000\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: -343460282368.000000\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: -381506748416.000000\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: -435212877824.000000\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: -495318663168.000000\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: -554995875840.000000\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: -622259535872.000000\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: -703266422784.000000\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: -793788022784.000000\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: -895502319616.000000\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: -1019088338944.000000\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: -1126152929280.000000\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: -1277716987904.000000\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: -1429577138176.000000\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: -1633036926976.000000\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: -1849126813696.000000\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: -2068465188864.000000\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: -2343615856640.000000\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: -2627581509632.000000\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -2995443728384.000000\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: -3362580332544.000000\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: -3730181193728.000000\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: -4342538567680.000000\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: -4885118451712.000000\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: -5428918878208.000000\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: -6122886922240.000000\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: -6838029910016.000000\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: -7819800084480.000000\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: -8700157755392.000000\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: -9817769902080.000000\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: -11025905614848.000000\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: -12587000397824.000000\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: -14171050606592.000000\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: -16201168191488.000000\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: -17845708652544.000000\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: -20293552701440.000000\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: -23135627771904.000000\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: -25861552078848.000000\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: -29543653965824.000000\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: -33423234170880.000000\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: -37343100665856.000000\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: -42363816771584.000000\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: -48396949782528.000000\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: -54352328785920.000000\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: -61410998484992.000000\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: -68576648101888.000000\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: -77260530909184.000000\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: -87735041785856.000000\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: -98102916677632.000000\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: -110596699717632.000000\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: -125741492600832.000000\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: -143258869039104.000000\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: -159850713579520.000000\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: -180160204636160.000000\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: -205522959597568.000000\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: -232357613273088.000000\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: -265348481810432.000000\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: -291551775293440.000000\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: -336656884301824.000000\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -378879332057088.000000\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: -425311820840960.000000\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: -483476851654656.000000\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: -541888272662528.000000\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: -617763198468096.000000\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: -696776503853056.000000\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: -788045565526016.000000\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: -887212736512000.000000\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: -1010765456736256.000000\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: -1148459356782592.000000\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: -1294452811366400.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: -1483599547203584.000000\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: -1665743204646912.000000\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: -1890471328612352.000000\n",
      "\n",
      "Test set: Average loss: -inf, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 4 [00000/60000 (00%)]\tLoss: -2087379338788864.000000\n",
      "Train Epoch: 4 [00640/60000 (01%)]\tLoss: -2337636345708544.000000\n",
      "Train Epoch: 4 [01280/60000 (02%)]\tLoss: -2682201976078336.000000\n",
      "Train Epoch: 4 [01920/60000 (03%)]\tLoss: -3007303083098112.000000\n",
      "Train Epoch: 4 [02560/60000 (04%)]\tLoss: -3456526060617728.000000\n",
      "Train Epoch: 4 [03200/60000 (05%)]\tLoss: -3852240456515584.000000\n",
      "Train Epoch: 4 [03840/60000 (06%)]\tLoss: -4471679967297536.000000\n",
      "Train Epoch: 4 [04480/60000 (07%)]\tLoss: -5077385783279616.000000\n",
      "Train Epoch: 4 [05120/60000 (09%)]\tLoss: -5732023087923200.000000\n",
      "Train Epoch: 4 [05760/60000 (10%)]\tLoss: -6483282124341248.000000\n",
      "Train Epoch: 4 [06400/60000 (11%)]\tLoss: -7326061008257024.000000\n",
      "Train Epoch: 4 [07040/60000 (12%)]\tLoss: -8201407018565632.000000\n",
      "Train Epoch: 4 [07680/60000 (13%)]\tLoss: -9345155198877696.000000\n",
      "Train Epoch: 4 [08320/60000 (14%)]\tLoss: -10649035329241088.000000\n",
      "Train Epoch: 4 [08960/60000 (15%)]\tLoss: -12180473564364800.000000\n",
      "Train Epoch: 4 [09600/60000 (16%)]\tLoss: -13523405684867072.000000\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: -15762866057510912.000000\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: -17459248216670208.000000\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: -19959728784277504.000000\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: -22268046072610816.000000\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: -25215093717336064.000000\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: -28982057061318656.000000\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: -32849836172640256.000000\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: -37855545394200576.000000\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: -42109276709191680.000000\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: -47908904192966656.000000\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: -54965453855916032.000000\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: -62260601837060096.000000\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: -70453964918751232.000000\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: -79582789057380352.000000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: -89270319721742336.000000\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: -101346032591306752.000000\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: -116327514174914560.000000\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: -130005206896214016.000000\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: -148436200053538816.000000\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: -165515326484643840.000000\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: -190403407834513408.000000\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: -217210480572235776.000000\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: -250187222291054592.000000\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: -278562336048939008.000000\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -312479039950422016.000000\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: -359420386795847680.000000\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: -406690556337455104.000000\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: -452568228762222592.000000\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: -516683191319265280.000000\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: -590519795170934784.000000\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: -663768366460174336.000000\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: -758612170752655360.000000\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: -857271555271426048.000000\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: -968089889125957632.000000\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: -1110678817623506944.000000\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: -1247564166990921728.000000\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: -1436318565081808896.000000\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: -1596405396501692416.000000\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: -1812629031028260864.000000\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: -2062381035693277184.000000\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: -2314274064375480320.000000\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: -2633020561122394112.000000\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: -3002468012927221760.000000\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: -3390107159491510272.000000\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: -3870412596288946176.000000\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: -4385974698064740352.000000\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: -4964797476222533632.000000\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: -5676249669114527744.000000\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: -6343152399628107776.000000\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: -7250555706531643392.000000\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: -8200806431813795840.000000\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: -9259240305176084480.000000\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: -10506683525887950848.000000\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: -12134227916321980416.000000\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: -13392927937079017472.000000\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: -15237137690836074496.000000\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: -17432878904179163136.000000\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: -20011395299523166208.000000\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: -22609583057399709696.000000\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: -25286418882011070464.000000\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: -28892403604744306688.000000\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: -32918711831567007744.000000\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: -36808759781382684672.000000\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: -41826455861529149440.000000\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -47452406172207808512.000000\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: -54176139678383603712.000000\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: -61033380284450471936.000000\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: -69433209316008001536.000000\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: -78944890893851688960.000000\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: -89278831247411380224.000000\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: -102025249645892993024.000000\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: -115155986940700917760.000000\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: -129634619938045952000.000000\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: -144176945444964794368.000000\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: -165229153844503511040.000000\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: -190891315432144240640.000000\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: -216386791057014128640.000000\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: -242102116230881083392.000000\n",
      "\n",
      "Test set: Average loss: -257557695758060683264.0000, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 5 [00000/60000 (00%)]\tLoss: -270470184730571571200.000000\n",
      "Train Epoch: 5 [00640/60000 (01%)]\tLoss: -304818189110479945728.000000\n",
      "Train Epoch: 5 [01280/60000 (02%)]\tLoss: -346314180155211251712.000000\n",
      "Train Epoch: 5 [01920/60000 (03%)]\tLoss: -395799732860758261760.000000\n",
      "Train Epoch: 5 [02560/60000 (04%)]\tLoss: -438529745387761172480.000000\n",
      "Train Epoch: 5 [03200/60000 (05%)]\tLoss: -508298983049403564032.000000\n",
      "Train Epoch: 5 [03840/60000 (06%)]\tLoss: -569208373606612992000.000000\n",
      "Train Epoch: 5 [04480/60000 (07%)]\tLoss: -646163174842469187584.000000\n",
      "Train Epoch: 5 [05120/60000 (09%)]\tLoss: -731774211221480275968.000000\n",
      "Train Epoch: 5 [05760/60000 (10%)]\tLoss: -828925651276884082688.000000\n",
      "Train Epoch: 5 [06400/60000 (11%)]\tLoss: -952474659073143341056.000000\n",
      "Train Epoch: 5 [07040/60000 (12%)]\tLoss: -1075723473806740684800.000000\n",
      "Train Epoch: 5 [07680/60000 (13%)]\tLoss: -1218989733352837218304.000000\n",
      "Train Epoch: 5 [08320/60000 (14%)]\tLoss: -1378391405201383751680.000000\n",
      "Train Epoch: 5 [08960/60000 (15%)]\tLoss: -1560018481948492038144.000000\n",
      "Train Epoch: 5 [09600/60000 (16%)]\tLoss: -1778864994866050367488.000000\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: -1985886603274505682944.000000\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: -2261159278873342377984.000000\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: -2587252402254776369152.000000\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: -2904786575281881088000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: -3312632557536553205760.000000\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: -3696295898642106023936.000000\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: -4281668711658142302208.000000\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: -4843961983958788341760.000000\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: -5487590547004722249728.000000\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: -6155431587547306786816.000000\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: -7077461983508169752576.000000\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: -8039109419491104129024.000000\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: -9125999146361444892672.000000\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: -10255557664951353999360.000000\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: -11669128375691988959232.000000\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: -13167794601391789441024.000000\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: -14948584322148587274240.000000\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: -17048558785195921113088.000000\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: -19265437687370538287104.000000\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: -21695210751130213548032.000000\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: -24795036122849512259584.000000\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: -27779877840682601152512.000000\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: -31178760242057810280448.000000\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: -35810327401040225239040.000000\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: -40870612474750360879104.000000\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: -46563284000936606826496.000000\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: -52508211149451128995840.000000\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: -59382077778704853893120.000000\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: -67777530578061974568960.000000\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: -76596871181546461069312.000000\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: -85779764864950430859264.000000\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: -97850510744612438540288.000000\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: -110242750587273916448768.000000\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: -125779349646569946218496.000000\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: -142384148494282729193472.000000\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: -164501110091517121265664.000000\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: -183650794009465169379328.000000\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: -208234016834640192471040.000000\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: -238314909825735946403840.000000\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: -267988263079351689412608.000000\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: -301358423108692268285952.000000\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: -345256647986936855658496.000000\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: -388083610629018077888512.000000\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: -442188127169990306562048.000000\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: -505010063351280000040960.000000\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: -570392025704752178266112.000000\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: -650601315212205806845952.000000\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: -726413758417856129662976.000000\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: -831329399164297090695168.000000\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: -949418969540722226626560.000000\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: -1070773325387817801482240.000000\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: -1202006561204731182579712.000000\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: -1373684931921599096946688.000000\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: -1550446101206714372063232.000000\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: -1759891442225929152102400.000000\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: -1980424573470136055365632.000000\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: -2246192868177968751443968.000000\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: -2559690383794268002058240.000000\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: -2897262918039391279513600.000000\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: -3302402705292374975709184.000000\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: -3692564312818258819416064.000000\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: -4209404035353948429746176.000000\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: -4819474178898918417367040.000000\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: -5392901018262968987549696.000000\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: -6137976540615143845789696.000000\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: -6916611302123414805807104.000000\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: -7976495500073003051384832.000000\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: -8986421303384967403798528.000000\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: -10170016284621879543595008.000000\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: -11540122836423555139239936.000000\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: -13134510667280914497667072.000000\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: -14873645487198654280237056.000000\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: -16933557657343157096939520.000000\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: -19053763010492579583098880.000000\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: -21570824698114761721643008.000000\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: -24544598945964377187024896.000000\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: -27899185472628643422273536.000000\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: -31749583586506074985857024.000000\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 6 [00000/60000 (00%)]\tLoss: -34819458453450689574076416.000000\n",
      "Train Epoch: 6 [00640/60000 (01%)]\tLoss: -39163894961267201135345664.000000\n",
      "Train Epoch: 6 [01280/60000 (02%)]\tLoss: -44968292111268427518181376.000000\n",
      "Train Epoch: 6 [01920/60000 (03%)]\tLoss: -51415009501602238915674112.000000\n",
      "Train Epoch: 6 [02560/60000 (04%)]\tLoss: -56853031255869501466476544.000000\n",
      "Train Epoch: 6 [03200/60000 (05%)]\tLoss: -65232953590070018591162368.000000\n",
      "Train Epoch: 6 [03840/60000 (06%)]\tLoss: -73852725102402925733347328.000000\n",
      "Train Epoch: 6 [04480/60000 (07%)]\tLoss: -84838734264046851899523072.000000\n",
      "Train Epoch: 6 [05120/60000 (09%)]\tLoss: -95708607336688721156112384.000000\n",
      "Train Epoch: 6 [05760/60000 (10%)]\tLoss: -107390496860083248020062208.000000\n",
      "Train Epoch: 6 [06400/60000 (11%)]\tLoss: -122697153147217628067004416.000000\n",
      "Train Epoch: 6 [07040/60000 (12%)]\tLoss: -138933802036828075158667264.000000\n",
      "Train Epoch: 6 [07680/60000 (13%)]\tLoss: -157053513008226866988843008.000000\n",
      "Train Epoch: 6 [08320/60000 (14%)]\tLoss: -177665425220844003516219392.000000\n",
      "Train Epoch: 6 [08960/60000 (15%)]\tLoss: -201970375597017792277118976.000000\n",
      "Train Epoch: 6 [09600/60000 (16%)]\tLoss: -226596354660306348364791808.000000\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: -259664873530553628650110976.000000\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: -292626438178661540955160576.000000\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: -331728831695186994445418496.000000\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: -375186114105889725171630080.000000\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: -427979957775083513514557440.000000\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: -489734713206451338165092352.000000\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: -541604116743135246038335488.000000\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: -617752460746849012204699648.000000\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: -702891120622790307703947264.000000\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: -801677272060272288194363392.000000\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: -903093855415688955907014656.000000\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: -1025681619370549486332936192.000000\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: -1174290434302761005106593792.000000\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: -1305475340226662019482255360.000000\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: -1479229502301557386769334272.000000\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: -1689325521089091646856888320.000000\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: -1908658045995261163953192960.000000\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: -2163893395105115286521511936.000000\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: -2502090983438118156851216384.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: -2796650363694543353172459520.000000\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: -3159424918091830933311193088.000000\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: -3619707485923221306527973376.000000\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: -4077063957422663575829217280.000000\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: -4617851067870774225826480128.000000\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: -5276511987506173372591505408.000000\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: -5914413384082877558997123072.000000\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: -6749400974934715312279388160.000000\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: -7652498076977361241067487232.000000\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: -8741772116423901497582944256.000000\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: -9885231769486508780691652608.000000\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: -11017314061100262371069263872.000000\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: -12611882494805475382861496320.000000\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: -14421226517334841293795229696.000000\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: -16083922171105173242262847488.000000\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: -18420556190378797998467448832.000000\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: -20972086218821888829766500352.000000\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: -23489112276557892598311682048.000000\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: -26597605291540353690581860352.000000\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: -30336494091870808026896138240.000000\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: -34377895327910650400777175040.000000\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: -38910118085530790784766312448.000000\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: -44357821170703282024705163264.000000\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: -50126512950449388789109358592.000000\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: -57629673270955721804761530368.000000\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: -64240891899643567711031656448.000000\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: -72242956071965630134575169536.000000\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: -82307712145073290630299385856.000000\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: -92964487692305904198238601216.000000\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: -106607838919032733227966005248.000000\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: -120603884808899164580123508736.000000\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: -136433946724984714304633700352.000000\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: -158433846564070215675870707712.000000\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: -177362149237503916492892143616.000000\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: -198343604631427818698762616832.000000\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: -228429707046460670962315558912.000000\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: -256857465468437155655465304064.000000\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: -286919351588145852378362413056.000000\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: -331109292630383118515720683520.000000\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: -374861262515533122277379932160.000000\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: -426109328060931086065451663360.000000\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: -480935360685205996724713160704.000000\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: -550015195406715329711186116608.000000\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: -612761543317127346365696835584.000000\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: -702611516977185130674017796096.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6d4e81c0f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# save the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a7d002381dc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "    \n",
    "    # save the model!\n",
    "    # source for timestamp formatting: https://stackoverflow.com/q/10607688/781938\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # source for f-string: https://stackoverflow.com/a/42562236/781938\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f'{timestamp}-mnist_mobilenet-{epoch:05d}.pytorchmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(optimizer, torch.optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(type(optimizer), torch.optim.Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
