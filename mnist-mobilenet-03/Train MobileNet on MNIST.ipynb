{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "- PyTorch MNIST example - https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "- pytorch cifar10 code - https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "- LeNet for CIFAR-10 - https://github.com/kuangliu/pytorch-cifar/blob/master/models/lenet.py\n",
    "\n",
    "### My notes\n",
    "- My Google Doc - https://docs.google.com/document/d/1nPvFULraomLmBp4IuNVe51YXV1DQsSzgQWtuaZhbkjo/edit\n",
    "- Trello - https://trello.com/b/ycCGjD3A/mobile-dl\n",
    "- Using webcam - https://docs.google.com/document/d/17BVx5yioNaV11mip4U9gRAO7wLIJf-aOpIITJPjqeks/edit#\n",
    "- Installing pytorch - https://docs.google.com/document/d/1NfLbuhoOxonzS9FEeooyqpB90-62Gat-uZ2DOTaWRdg/edit#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "/Users/william/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenet.py\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.size())\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "#         print(out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [(48,2), (64,2), (128,2), (256,2), 256]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layers = self._make_layers(in_planes=16)\n",
    "        self.linear = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.size())\n",
    "        out = self.layers(out)\n",
    "#         print(out.size())\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "#         print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.size())\n",
    "        out = self.linear(out)\n",
    "#         print(out.size())\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, epochs=10, log_interval=10, lr=0.01, momentum=0.5, no_cuda=False, seed=1, test_batch_size=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(args=[\"--epochs=10\"])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11649b1d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "#                        transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "#                        transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.5\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # to do: needed?\n",
    "        optimizer.zero_grad()  # what does this do? zero-out any previous gradient info?\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            digits = int(math.log10(len(train_loader.dataset))) + 1\n",
    "            print('Train Epoch: {} [{:05d}/{:05d} ({:02.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/60000 (00%)]\tLoss: -0.027056\n",
      "Train Epoch: 1 [00640/60000 (01%)]\tLoss: -0.360708\n",
      "Train Epoch: 1 [01280/60000 (02%)]\tLoss: -0.707185\n",
      "Train Epoch: 1 [01920/60000 (03%)]\tLoss: -1.043764\n",
      "Train Epoch: 1 [02560/60000 (04%)]\tLoss: -1.472964\n",
      "Train Epoch: 1 [03200/60000 (05%)]\tLoss: -1.841768\n",
      "Train Epoch: 1 [03840/60000 (06%)]\tLoss: -2.332770\n",
      "Train Epoch: 1 [04480/60000 (07%)]\tLoss: -2.791593\n",
      "Train Epoch: 1 [05120/60000 (09%)]\tLoss: -3.270411\n",
      "Train Epoch: 1 [05760/60000 (10%)]\tLoss: -4.022709\n",
      "Train Epoch: 1 [06400/60000 (11%)]\tLoss: -4.550189\n",
      "Train Epoch: 1 [07040/60000 (12%)]\tLoss: -5.370422\n",
      "Train Epoch: 1 [07680/60000 (13%)]\tLoss: -6.216835\n",
      "Train Epoch: 1 [08320/60000 (14%)]\tLoss: -7.565855\n",
      "Train Epoch: 1 [08960/60000 (15%)]\tLoss: -8.563569\n",
      "Train Epoch: 1 [09600/60000 (16%)]\tLoss: -10.175191\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: -11.554020\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: -12.635107\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: -14.026346\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: -17.309227\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -18.214174\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: -23.244022\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: -26.113298\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: -29.123690\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: -31.745043\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: -38.221550\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: -44.888626\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: -56.611908\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: -55.190956\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: -67.185883\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -71.723022\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: -85.211655\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: -94.079056\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: -114.394966\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: -112.350090\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: -114.567581\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: -152.224915\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: -155.053497\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: -184.713608\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: -229.965637\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -202.204605\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: -318.442566\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: -318.242889\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: -346.654907\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: -465.340942\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: -471.396545\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: -615.893921\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: -579.741577\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: -739.145386\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: -776.906250\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -841.763306\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: -1021.784729\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: -1230.493164\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: -1227.630249\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: -1630.063477\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: -1689.176270\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: -1630.382324\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: -1976.102661\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: -2381.592041\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: -2800.218018\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: -3160.615479\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: -3482.129150\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: -3627.011475\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: -4352.482910\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: -4661.701172\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: -5422.693359\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: -6110.279297\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: -8001.288574\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: -7664.155273\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: -8363.890625\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: -9562.951172\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: -12788.386719\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: -11273.328125\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: -13552.065430\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: -15415.171875\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: -17716.498047\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: -17597.490234\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: -21806.275391\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: -27125.376953\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: -28527.445312\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -32165.279297\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: -36172.500000\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: -41929.156250\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: -41069.464844\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: -50668.839844\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: -59755.523438\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: -68067.195312\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: -80447.015625\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: -99788.710938\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: -99471.265625\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: -115526.406250\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: -121950.968750\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: -152162.812500\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: -156744.812500\n",
      "\n",
      "Test set: Average loss: -84395.4376, Accuracy: 1341/10000 (13%)\n",
      "\n",
      "Train Epoch: 2 [00000/60000 (00%)]\tLoss: -150716.000000\n",
      "Train Epoch: 2 [00640/60000 (01%)]\tLoss: -190277.609375\n",
      "Train Epoch: 2 [01280/60000 (02%)]\tLoss: -231205.500000\n",
      "Train Epoch: 2 [01920/60000 (03%)]\tLoss: -251704.296875\n",
      "Train Epoch: 2 [02560/60000 (04%)]\tLoss: -280416.656250\n",
      "Train Epoch: 2 [03200/60000 (05%)]\tLoss: -328161.875000\n",
      "Train Epoch: 2 [03840/60000 (06%)]\tLoss: -375424.406250\n",
      "Train Epoch: 2 [04480/60000 (07%)]\tLoss: -432604.625000\n",
      "Train Epoch: 2 [05120/60000 (09%)]\tLoss: -421221.281250\n",
      "Train Epoch: 2 [05760/60000 (10%)]\tLoss: -572074.750000\n",
      "Train Epoch: 2 [06400/60000 (11%)]\tLoss: -677718.312500\n",
      "Train Epoch: 2 [07040/60000 (12%)]\tLoss: -684058.812500\n",
      "Train Epoch: 2 [07680/60000 (13%)]\tLoss: -916780.875000\n",
      "Train Epoch: 2 [08320/60000 (14%)]\tLoss: -1043168.250000\n",
      "Train Epoch: 2 [08960/60000 (15%)]\tLoss: -1050912.750000\n",
      "Train Epoch: 2 [09600/60000 (16%)]\tLoss: -1189890.375000\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: -1460461.250000\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: -1603104.750000\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: -1726151.750000\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: -1629523.500000\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: -2031070.500000\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: -2720160.500000\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: -2724212.250000\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: -3295189.000000\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: -3614004.000000\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: -3432297.250000\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: -5122316.000000\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: -4478550.000000\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: -5832819.500000\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: -6439836.500000\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: -8056151.000000\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: -8640045.000000\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: -6232388.500000\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: -10749259.000000\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: -12633690.000000\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: -12621343.000000\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: -15349890.000000\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: -15639719.000000\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: -19000650.000000\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: -18385034.000000\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -25718984.000000\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: -32546922.000000\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: -31731182.000000\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: -37286320.000000\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: -46109360.000000\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: -45498644.000000\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: -57269332.000000\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: -58017072.000000\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: -68245832.000000\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: -79943600.000000\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: -91437536.000000\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: -109531312.000000\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: -128785744.000000\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: -121908960.000000\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: -134756320.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: -204192800.000000\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: -190855024.000000\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: -196809104.000000\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: -197768160.000000\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: -230236800.000000\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: -346967424.000000\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: -389362048.000000\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: -274205472.000000\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: -431194816.000000\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: -513286784.000000\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: -541571392.000000\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: -619272896.000000\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: -748308800.000000\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: -776496576.000000\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: -944330880.000000\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: -957918528.000000\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: -1277229312.000000\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: -1275750016.000000\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: -1548602496.000000\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: -1939114752.000000\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: -2008851200.000000\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: -1736826496.000000\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: -2631956480.000000\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: -1548418816.000000\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: -3260294400.000000\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -4079193088.000000\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: -4170415360.000000\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: -4182888448.000000\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: -5891166720.000000\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: -6128267776.000000\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: -7409027584.000000\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: -8872182784.000000\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: -8818849792.000000\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: -9588559872.000000\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: -11759288320.000000\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: -14981829632.000000\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: -12560024576.000000\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: -15596278784.000000\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: -19665694720.000000\n",
      "\n",
      "Test set: Average loss: -7179871872.6144, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 3 [00000/60000 (00%)]\tLoss: -21735569408.000000\n",
      "Train Epoch: 3 [00640/60000 (01%)]\tLoss: -18537736192.000000\n",
      "Train Epoch: 3 [01280/60000 (02%)]\tLoss: -26087858176.000000\n",
      "Train Epoch: 3 [01920/60000 (03%)]\tLoss: -25163053056.000000\n",
      "Train Epoch: 3 [02560/60000 (04%)]\tLoss: -28542042112.000000\n",
      "Train Epoch: 3 [03200/60000 (05%)]\tLoss: -37401702400.000000\n",
      "Train Epoch: 3 [03840/60000 (06%)]\tLoss: -50117427200.000000\n",
      "Train Epoch: 3 [04480/60000 (07%)]\tLoss: -49695145984.000000\n",
      "Train Epoch: 3 [05120/60000 (09%)]\tLoss: -50136334336.000000\n",
      "Train Epoch: 3 [05760/60000 (10%)]\tLoss: -75708080128.000000\n",
      "Train Epoch: 3 [06400/60000 (11%)]\tLoss: -83381567488.000000\n",
      "Train Epoch: 3 [07040/60000 (12%)]\tLoss: -72871510016.000000\n",
      "Train Epoch: 3 [07680/60000 (13%)]\tLoss: -78071595008.000000\n",
      "Train Epoch: 3 [08320/60000 (14%)]\tLoss: -95672541184.000000\n",
      "Train Epoch: 3 [08960/60000 (15%)]\tLoss: -113083932672.000000\n",
      "Train Epoch: 3 [09600/60000 (16%)]\tLoss: -118477160448.000000\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: -155644559360.000000\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: -119345946624.000000\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: -166027509760.000000\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: -216275697664.000000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: -251438972928.000000\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: -308399702016.000000\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: -373648031744.000000\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: -308541620224.000000\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: -324202004480.000000\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: -415160860672.000000\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: -483852189696.000000\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: -531745374208.000000\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: -643534422016.000000\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: -765214130176.000000\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: -720508944384.000000\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: -734636015616.000000\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: -948827193344.000000\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: -1091802234880.000000\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: -1234085085184.000000\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: -1443099312128.000000\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: -1669731188736.000000\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: -2242523955200.000000\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: -2259094077440.000000\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: -2719058493440.000000\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -2850005450752.000000\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: -2879855525888.000000\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: -3915665113088.000000\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: -3335496400896.000000\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: -4465106616320.000000\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: -5717916909568.000000\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: -5936392962048.000000\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: -6507668176896.000000\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: -8363319492608.000000\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: -8789069660160.000000\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: -10618766622720.000000\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: -11433568894976.000000\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: -9752239144960.000000\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: -12598917464064.000000\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: -13589059469312.000000\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: -16262248792064.000000\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: -19211468406784.000000\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: -20044696256512.000000\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: -25934937718784.000000\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: -30301038313472.000000\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: -23824282157056.000000\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: -39390311088128.000000\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: -44741886476288.000000\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: -45213158473728.000000\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: -62415702065152.000000\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: -52440334336000.000000\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: -71089359159296.000000\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: -82059125063680.000000\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: -71733730082816.000000\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: -111359501008896.000000\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: -114684426452992.000000\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: -125814129557504.000000\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: -141913957072896.000000\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: -162672020553728.000000\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: -173482470014976.000000\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: -204977062543360.000000\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: -259464611495936.000000\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: -260597576892416.000000\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: -291224518918144.000000\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: -284566547857408.000000\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -350689012219904.000000\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: -447548275818496.000000\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: -465312260554752.000000\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: -516038273794048.000000\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: -691025207099392.000000\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: -645088787038208.000000\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: -863215881814016.000000\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: -920190300717056.000000\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: -1206306258026496.000000\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: -848244095582208.000000\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: -1090664464908288.000000\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: -1163077680627712.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: -1306882446721024.000000\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: -1410198421897216.000000\n",
      "\n",
      "Test set: Average loss: -1617007207005343.0000, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 4 [00000/60000 (00%)]\tLoss: -1738940855877632.000000\n",
      "Train Epoch: 4 [00640/60000 (01%)]\tLoss: -1642117931728896.000000\n",
      "Train Epoch: 4 [01280/60000 (02%)]\tLoss: -1923532644679680.000000\n",
      "Train Epoch: 4 [01920/60000 (03%)]\tLoss: -2431691834523648.000000\n",
      "Train Epoch: 4 [02560/60000 (04%)]\tLoss: -2653914516160512.000000\n",
      "Train Epoch: 4 [03200/60000 (05%)]\tLoss: -2820465563271168.000000\n",
      "Train Epoch: 4 [03840/60000 (06%)]\tLoss: -3320549275074560.000000\n",
      "Train Epoch: 4 [04480/60000 (07%)]\tLoss: -3671620438720512.000000\n",
      "Train Epoch: 4 [05120/60000 (09%)]\tLoss: -4117230006566912.000000\n",
      "Train Epoch: 4 [05760/60000 (10%)]\tLoss: -4414696220262400.000000\n",
      "Train Epoch: 4 [06400/60000 (11%)]\tLoss: -5195522079981568.000000\n",
      "Train Epoch: 4 [07040/60000 (12%)]\tLoss: -5641115810136064.000000\n",
      "Train Epoch: 4 [07680/60000 (13%)]\tLoss: -6499174577078272.000000\n",
      "Train Epoch: 4 [08320/60000 (14%)]\tLoss: -7520982193405952.000000\n",
      "Train Epoch: 4 [08960/60000 (15%)]\tLoss: -8133455267233792.000000\n",
      "Train Epoch: 4 [09600/60000 (16%)]\tLoss: -8777353543024640.000000\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: -10339000967495680.000000\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: -11431891903184896.000000\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: -12964650840752128.000000\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: -15112507077165056.000000\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: -17196066579415040.000000\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: -18485614403911680.000000\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: -20696137434398720.000000\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: -22611765862858752.000000\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: -26171252221673472.000000\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: -29492653510885376.000000\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: -33678672518971392.000000\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: -36940734540021760.000000\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: -42660759099932672.000000\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: -47472956422488064.000000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: -52096712054931456.000000\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: -59883492057546752.000000\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: -68489141934882816.000000\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: -76181991002734592.000000\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: -83561002515300352.000000\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: -94047577485344768.000000\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: -106091447467376640.000000\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: -120275147465687040.000000\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: -136366440008646656.000000\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: -153046039991943168.000000\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -173286846468456448.000000\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: -198153143744200704.000000\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: -223002381409845248.000000\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: -245493424331948032.000000\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: -273272860485615616.000000\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: -310544758478995456.000000\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: -358440515777069056.000000\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: -400198111974129664.000000\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: -453749825804959744.000000\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: -511771604158513152.000000\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: -561347140345921536.000000\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: -640505998951317504.000000\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: -720481519818244096.000000\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: -809420259474800640.000000\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: -916502109220765696.000000\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: -1046050829812891648.000000\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: -1176785442415050752.000000\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: -1309670081285849088.000000\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: -1491353382659555328.000000\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: -1673162715553595392.000000\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: -1892521332608860160.000000\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: -2114524000251019264.000000\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: -2430049340245409792.000000\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: -2704878044044066816.000000\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: -3071338122756227072.000000\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: -3472530949156110336.000000\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: -3862948836481695744.000000\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: -4315450372991746048.000000\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: -4870362071780294656.000000\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: -5572721853266395136.000000\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: -6249513041604378624.000000\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: -7063028500856307712.000000\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: -8000703012139958272.000000\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: -9042366584399593472.000000\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: -10099997264517791744.000000\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: -11433535544219402240.000000\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: -12861609833677193216.000000\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: -14501230160319086592.000000\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: -16530067707589033984.000000\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: -18418265623038525440.000000\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -21089479644697067520.000000\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: -23607488815652929536.000000\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: -26930248139164090368.000000\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: -30330369100805570560.000000\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: -34052910852176084992.000000\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: -38340137586316541952.000000\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: -43074128880171220992.000000\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: -49057248946063147008.000000\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: -55507718628364517376.000000\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: -62485663620928634880.000000\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: -70886908823462739968.000000\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: -79549543124291289088.000000\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: -89743432084751384576.000000\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: -101163426043763097600.000000\n",
      "\n",
      "Test set: Average loss: -112237036375705976832.0000, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 5 [00000/60000 (00%)]\tLoss: -112015570625540128768.000000\n",
      "Train Epoch: 5 [00640/60000 (01%)]\tLoss: -126388483380851245056.000000\n",
      "Train Epoch: 5 [01280/60000 (02%)]\tLoss: -141112518577422860288.000000\n",
      "Train Epoch: 5 [01920/60000 (03%)]\tLoss: -162670827781180358656.000000\n",
      "Train Epoch: 5 [02560/60000 (04%)]\tLoss: -182468053608775548928.000000\n",
      "Train Epoch: 5 [03200/60000 (05%)]\tLoss: -206533460430094860288.000000\n",
      "Train Epoch: 5 [03840/60000 (06%)]\tLoss: -233651058753562214400.000000\n",
      "Train Epoch: 5 [04480/60000 (07%)]\tLoss: -261974407916327796736.000000\n",
      "Train Epoch: 5 [05120/60000 (09%)]\tLoss: -294673637435781414912.000000\n",
      "Train Epoch: 5 [05760/60000 (10%)]\tLoss: -335650359925039693824.000000\n",
      "Train Epoch: 5 [06400/60000 (11%)]\tLoss: -385326963771029061632.000000\n",
      "Train Epoch: 5 [07040/60000 (12%)]\tLoss: -428941933624810274816.000000\n",
      "Train Epoch: 5 [07680/60000 (13%)]\tLoss: -481679120445690871808.000000\n",
      "Train Epoch: 5 [08320/60000 (14%)]\tLoss: -543959364508225372160.000000\n",
      "Train Epoch: 5 [08960/60000 (15%)]\tLoss: -632841527144707260416.000000\n",
      "Train Epoch: 5 [09600/60000 (16%)]\tLoss: -705335407396536713216.000000\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: -794266652232082522112.000000\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: -897202121583913598976.000000\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: -1020196623676052865024.000000\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: -1148150855595322245120.000000\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: -1287531001244207284224.000000\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: -1457343165843885785088.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: -1657092305279067881472.000000\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: -1896116914852083007488.000000\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: nan\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: nan\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: nan\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: nan\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: nan\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: nan\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: nan\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: nan\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: nan\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: nan\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: nan\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: nan\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: nan\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: nan\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: nan\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: nan\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: nan\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: nan\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: nan\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: nan\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: nan\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: nan\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: nan\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: nan\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: nan\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: nan\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: nan\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: nan\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: nan\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: nan\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: nan\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: nan\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: nan\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: nan\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: nan\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: nan\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: nan\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: nan\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: nan\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: nan\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: nan\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: nan\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: nan\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: nan\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: nan\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: nan\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: nan\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: nan\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: nan\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: nan\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: nan\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: nan\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: nan\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: nan\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: nan\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: nan\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: nan\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: nan\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: nan\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: nan\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: nan\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: nan\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: nan\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: nan\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: nan\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: nan\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: nan\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: nan\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: nan\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: nan\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 6 [00000/60000 (00%)]\tLoss: nan\n",
      "Train Epoch: 6 [00640/60000 (01%)]\tLoss: nan\n",
      "Train Epoch: 6 [01280/60000 (02%)]\tLoss: nan\n",
      "Train Epoch: 6 [01920/60000 (03%)]\tLoss: nan\n",
      "Train Epoch: 6 [02560/60000 (04%)]\tLoss: nan\n",
      "Train Epoch: 6 [03200/60000 (05%)]\tLoss: nan\n",
      "Train Epoch: 6 [03840/60000 (06%)]\tLoss: nan\n",
      "Train Epoch: 6 [04480/60000 (07%)]\tLoss: nan\n",
      "Train Epoch: 6 [05120/60000 (09%)]\tLoss: nan\n",
      "Train Epoch: 6 [05760/60000 (10%)]\tLoss: nan\n",
      "Train Epoch: 6 [06400/60000 (11%)]\tLoss: nan\n",
      "Train Epoch: 6 [07040/60000 (12%)]\tLoss: nan\n",
      "Train Epoch: 6 [07680/60000 (13%)]\tLoss: nan\n",
      "Train Epoch: 6 [08320/60000 (14%)]\tLoss: nan\n",
      "Train Epoch: 6 [08960/60000 (15%)]\tLoss: nan\n",
      "Train Epoch: 6 [09600/60000 (16%)]\tLoss: nan\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: nan\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: nan\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: nan\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: nan\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: nan\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: nan\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: nan\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: nan\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: nan\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: nan\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: nan\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: nan\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: nan\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: nan\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: nan\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: nan\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: nan\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: nan\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: nan\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: nan\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: nan\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: nan\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: nan\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: nan\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: nan\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: nan\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: nan\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: nan\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: nan\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: nan\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: nan\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: nan\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: nan\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: nan\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: nan\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: nan\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: nan\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: nan\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: nan\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: nan\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: nan\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: nan\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: nan\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: nan\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: nan\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: nan\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: nan\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: nan\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: nan\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: nan\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: nan\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: nan\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: nan\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: nan\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: nan\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: nan\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: nan\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: nan\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: nan\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: nan\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: nan\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: nan\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: nan\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: nan\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: nan\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: nan\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: nan\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: nan\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: nan\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: nan\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: nan\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: nan\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: nan\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: nan\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: nan\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: nan\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: nan\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: nan\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 7 [00000/60000 (00%)]\tLoss: nan\n",
      "Train Epoch: 7 [00640/60000 (01%)]\tLoss: nan\n",
      "Train Epoch: 7 [01280/60000 (02%)]\tLoss: nan\n",
      "Train Epoch: 7 [01920/60000 (03%)]\tLoss: nan\n",
      "Train Epoch: 7 [02560/60000 (04%)]\tLoss: nan\n",
      "Train Epoch: 7 [03200/60000 (05%)]\tLoss: nan\n",
      "Train Epoch: 7 [03840/60000 (06%)]\tLoss: nan\n",
      "Train Epoch: 7 [04480/60000 (07%)]\tLoss: nan\n",
      "Train Epoch: 7 [05120/60000 (09%)]\tLoss: nan\n",
      "Train Epoch: 7 [05760/60000 (10%)]\tLoss: nan\n",
      "Train Epoch: 7 [06400/60000 (11%)]\tLoss: nan\n",
      "Train Epoch: 7 [07040/60000 (12%)]\tLoss: nan\n",
      "Train Epoch: 7 [07680/60000 (13%)]\tLoss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [08320/60000 (14%)]\tLoss: nan\n",
      "Train Epoch: 7 [08960/60000 (15%)]\tLoss: nan\n",
      "Train Epoch: 7 [09600/60000 (16%)]\tLoss: nan\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: nan\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: nan\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: nan\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: nan\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: nan\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: nan\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: nan\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: nan\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: nan\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: nan\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: nan\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: nan\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: nan\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: nan\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: nan\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: nan\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: nan\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: nan\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: nan\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: nan\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: nan\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: nan\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: nan\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: nan\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: nan\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: nan\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: nan\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: nan\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: nan\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: nan\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: nan\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: nan\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: nan\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: nan\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: nan\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: nan\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: nan\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: nan\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: nan\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: nan\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: nan\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: nan\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: nan\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: nan\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: nan\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: nan\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: nan\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: nan\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: nan\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: nan\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: nan\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: nan\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: nan\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: nan\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: nan\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: nan\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: nan\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: nan\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: nan\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: nan\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: nan\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: nan\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: nan\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: nan\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: nan\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: nan\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: nan\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: nan\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: nan\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: nan\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: nan\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: nan\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: nan\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: nan\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: nan\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: nan\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: nan\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: nan\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 8 [00000/60000 (00%)]\tLoss: nan\n",
      "Train Epoch: 8 [00640/60000 (01%)]\tLoss: nan\n",
      "Train Epoch: 8 [01280/60000 (02%)]\tLoss: nan\n",
      "Train Epoch: 8 [01920/60000 (03%)]\tLoss: nan\n",
      "Train Epoch: 8 [02560/60000 (04%)]\tLoss: nan\n",
      "Train Epoch: 8 [03200/60000 (05%)]\tLoss: nan\n",
      "Train Epoch: 8 [03840/60000 (06%)]\tLoss: nan\n",
      "Train Epoch: 8 [04480/60000 (07%)]\tLoss: nan\n",
      "Train Epoch: 8 [05120/60000 (09%)]\tLoss: nan\n",
      "Train Epoch: 8 [05760/60000 (10%)]\tLoss: nan\n",
      "Train Epoch: 8 [06400/60000 (11%)]\tLoss: nan\n",
      "Train Epoch: 8 [07040/60000 (12%)]\tLoss: nan\n",
      "Train Epoch: 8 [07680/60000 (13%)]\tLoss: nan\n",
      "Train Epoch: 8 [08320/60000 (14%)]\tLoss: nan\n",
      "Train Epoch: 8 [08960/60000 (15%)]\tLoss: nan\n",
      "Train Epoch: 8 [09600/60000 (16%)]\tLoss: nan\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: nan\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: nan\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: nan\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: nan\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: nan\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: nan\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: nan\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: nan\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: nan\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: nan\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: nan\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: nan\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: nan\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: nan\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: nan\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: nan\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: nan\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: nan\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: nan\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: nan\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: nan\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: nan\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: nan\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: nan\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: nan\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: nan\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: nan\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: nan\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: nan\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: nan\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: nan\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: nan\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: nan\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: nan\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: nan\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: nan\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: nan\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: nan\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: nan\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: nan\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: nan\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: nan\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: nan\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: nan\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: nan\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: nan\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: nan\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: nan\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: nan\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: nan\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: nan\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: nan\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: nan\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: nan\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: nan\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: nan\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: nan\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: nan\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: nan\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: nan\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: nan\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: nan\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: nan\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: nan\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: nan\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: nan\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: nan\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: nan\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: nan\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: nan\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: nan\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: nan\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: nan\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: nan\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: nan\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: nan\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: nan\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: nan\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 980/10000 (10%)\n",
      "\n",
      "Train Epoch: 9 [00000/60000 (00%)]\tLoss: nan\n",
      "Train Epoch: 9 [00640/60000 (01%)]\tLoss: nan\n",
      "Train Epoch: 9 [01280/60000 (02%)]\tLoss: nan\n",
      "Train Epoch: 9 [01920/60000 (03%)]\tLoss: nan\n",
      "Train Epoch: 9 [02560/60000 (04%)]\tLoss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [03200/60000 (05%)]\tLoss: nan\n",
      "Train Epoch: 9 [03840/60000 (06%)]\tLoss: nan\n",
      "Train Epoch: 9 [04480/60000 (07%)]\tLoss: nan\n",
      "Train Epoch: 9 [05120/60000 (09%)]\tLoss: nan\n",
      "Train Epoch: 9 [05760/60000 (10%)]\tLoss: nan\n",
      "Train Epoch: 9 [06400/60000 (11%)]\tLoss: nan\n",
      "Train Epoch: 9 [07040/60000 (12%)]\tLoss: nan\n",
      "Train Epoch: 9 [07680/60000 (13%)]\tLoss: nan\n",
      "Train Epoch: 9 [08320/60000 (14%)]\tLoss: nan\n",
      "Train Epoch: 9 [08960/60000 (15%)]\tLoss: nan\n",
      "Train Epoch: 9 [09600/60000 (16%)]\tLoss: nan\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: nan\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: nan\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: nan\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: nan\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: nan\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: nan\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: nan\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: nan\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: nan\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: nan\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: nan\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: nan\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: nan\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: nan\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: nan\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: nan\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: nan\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: nan\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: nan\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6d4e81c0f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# save the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a7d002381dc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# to do: needed?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# what does this do? zero-out any previous gradient info?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9dd0f0e3ff6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#         print(out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#         print(out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a9dd0f0e3ff6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(out.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "    \n",
    "    # save the model!\n",
    "    # source for timestamp formatting: https://stackoverflow.com/q/10607688/781938\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # source for f-string: https://stackoverflow.com/a/42562236/781938\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f'{timestamp}-mnist_mobilenet-{epoch:05d}.pytorchmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
