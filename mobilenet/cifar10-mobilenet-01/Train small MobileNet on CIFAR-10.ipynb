{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "- pytorch cifar10 code - https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n",
      "/Users/william/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenet.py\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.size())\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "#         print(out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [(48,2), (64,2), (128,2), (256,2), 256]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layers = self._make_layers(in_planes=16)\n",
    "        self.linear = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "#         print(out.size())\n",
    "        out = self.layers(out)\n",
    "#         print(out.size())\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "#         print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(out.size())\n",
    "        out = self.linear(out)\n",
    "#         print(out.size())\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR-10 Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=64, epochs=10, log_interval=10, lr=0.01, momentum=0.5, no_cuda=False, seed=1, test_batch_size=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(args=[\"--epochs=10\"])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ed60210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.4914, 0.4822, 0.4465],\n",
    "    std=[0.2023, 0.1994, 0.2010],\n",
    ")\n",
    "train_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=data_dir, train=True,\n",
    "    download=True, transform=train_transform,\n",
    ")\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(\n",
    "    root=data_dir, train=True,\n",
    "    download=True, transform=valid_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.1\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, sampler=train_sampler, num_workers=3)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset, batch_size=args.test_batch_size, sampler=valid_sampler, num_workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Block(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.5\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  # to do: needed?\n",
    "        optimizer.zero_grad()  # what does this do? zero-out any previous gradient info?\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            digits = int(math.log10(len(train_loader.dataset))) + 1\n",
    "            print('Train Epoch: {} [{:05d}/{:05d} ({:02.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/50000 (00%)]\tLoss: 2.340225\n",
      "Train Epoch: 1 [00640/50000 (01%)]\tLoss: 2.287353\n",
      "Train Epoch: 1 [01280/50000 (03%)]\tLoss: 2.282860\n",
      "Train Epoch: 1 [01920/50000 (04%)]\tLoss: 2.280152\n",
      "Train Epoch: 1 [02560/50000 (06%)]\tLoss: 2.228048\n",
      "Train Epoch: 1 [03200/50000 (07%)]\tLoss: 2.229302\n",
      "Train Epoch: 1 [03840/50000 (09%)]\tLoss: 2.233533\n",
      "Train Epoch: 1 [04480/50000 (10%)]\tLoss: 2.199833\n",
      "Train Epoch: 1 [05120/50000 (11%)]\tLoss: 2.191037\n",
      "Train Epoch: 1 [05760/50000 (13%)]\tLoss: 2.157562\n",
      "Train Epoch: 1 [06400/50000 (14%)]\tLoss: 2.178512\n",
      "Train Epoch: 1 [07040/50000 (16%)]\tLoss: 2.144815\n",
      "Train Epoch: 1 [07680/50000 (17%)]\tLoss: 2.029194\n",
      "Train Epoch: 1 [08320/50000 (18%)]\tLoss: 2.047235\n",
      "Train Epoch: 1 [08960/50000 (20%)]\tLoss: 1.994708\n",
      "Train Epoch: 1 [09600/50000 (21%)]\tLoss: 2.058118\n",
      "Train Epoch: 1 [10240/50000 (23%)]\tLoss: 2.071334\n",
      "Train Epoch: 1 [10880/50000 (24%)]\tLoss: 1.958049\n",
      "Train Epoch: 1 [11520/50000 (26%)]\tLoss: 2.081695\n",
      "Train Epoch: 1 [12160/50000 (27%)]\tLoss: 1.914077\n",
      "Train Epoch: 1 [12800/50000 (28%)]\tLoss: 2.033386\n",
      "Train Epoch: 1 [13440/50000 (30%)]\tLoss: 1.943752\n",
      "Train Epoch: 1 [14080/50000 (31%)]\tLoss: 1.933820\n",
      "Train Epoch: 1 [14720/50000 (33%)]\tLoss: 1.874731\n",
      "Train Epoch: 1 [15360/50000 (34%)]\tLoss: 1.808107\n",
      "Train Epoch: 1 [16000/50000 (36%)]\tLoss: 1.958905\n",
      "Train Epoch: 1 [16640/50000 (37%)]\tLoss: 1.850447\n",
      "Train Epoch: 1 [17280/50000 (38%)]\tLoss: 1.764664\n",
      "Train Epoch: 1 [17920/50000 (40%)]\tLoss: 1.923254\n",
      "Train Epoch: 1 [18560/50000 (41%)]\tLoss: 1.945044\n",
      "Train Epoch: 1 [19200/50000 (43%)]\tLoss: 1.846305\n",
      "Train Epoch: 1 [19840/50000 (44%)]\tLoss: 1.881551\n",
      "Train Epoch: 1 [20480/50000 (45%)]\tLoss: 1.796349\n",
      "Train Epoch: 1 [21120/50000 (47%)]\tLoss: 1.682783\n",
      "Train Epoch: 1 [21760/50000 (48%)]\tLoss: 1.823919\n",
      "Train Epoch: 1 [22400/50000 (50%)]\tLoss: 1.816125\n",
      "Train Epoch: 1 [23040/50000 (51%)]\tLoss: 1.858429\n",
      "Train Epoch: 1 [23680/50000 (53%)]\tLoss: 1.652398\n",
      "Train Epoch: 1 [24320/50000 (54%)]\tLoss: 1.738966\n",
      "Train Epoch: 1 [24960/50000 (55%)]\tLoss: 1.881653\n",
      "Train Epoch: 1 [25600/50000 (57%)]\tLoss: 1.851143\n",
      "Train Epoch: 1 [26240/50000 (58%)]\tLoss: 1.551465\n",
      "Train Epoch: 1 [26880/50000 (60%)]\tLoss: 1.655161\n",
      "Train Epoch: 1 [27520/50000 (61%)]\tLoss: 1.782428\n",
      "Train Epoch: 1 [28160/50000 (62%)]\tLoss: 1.805815\n",
      "Train Epoch: 1 [28800/50000 (64%)]\tLoss: 1.830334\n",
      "Train Epoch: 1 [29440/50000 (65%)]\tLoss: 1.781272\n",
      "Train Epoch: 1 [30080/50000 (67%)]\tLoss: 1.770859\n",
      "Train Epoch: 1 [30720/50000 (68%)]\tLoss: 1.676314\n",
      "Train Epoch: 1 [31360/50000 (70%)]\tLoss: 1.688004\n",
      "Train Epoch: 1 [32000/50000 (71%)]\tLoss: 1.757464\n",
      "Train Epoch: 1 [32640/50000 (72%)]\tLoss: 1.813138\n",
      "Train Epoch: 1 [33280/50000 (74%)]\tLoss: 1.643484\n",
      "Train Epoch: 1 [33920/50000 (75%)]\tLoss: 1.748659\n",
      "Train Epoch: 1 [34560/50000 (77%)]\tLoss: 1.794506\n",
      "Train Epoch: 1 [35200/50000 (78%)]\tLoss: 1.615827\n",
      "Train Epoch: 1 [35840/50000 (80%)]\tLoss: 1.849572\n",
      "Train Epoch: 1 [36480/50000 (81%)]\tLoss: 1.715659\n",
      "Train Epoch: 1 [37120/50000 (82%)]\tLoss: 1.760770\n",
      "Train Epoch: 1 [37760/50000 (84%)]\tLoss: 1.644613\n",
      "Train Epoch: 1 [38400/50000 (85%)]\tLoss: 1.595524\n",
      "Train Epoch: 1 [39040/50000 (87%)]\tLoss: 1.736053\n",
      "Train Epoch: 1 [39680/50000 (88%)]\tLoss: 1.605153\n",
      "Train Epoch: 1 [40320/50000 (89%)]\tLoss: 1.643459\n",
      "Train Epoch: 1 [40960/50000 (91%)]\tLoss: 1.648186\n",
      "Train Epoch: 1 [41600/50000 (92%)]\tLoss: 1.607366\n",
      "Train Epoch: 1 [42240/50000 (94%)]\tLoss: 1.657842\n",
      "Train Epoch: 1 [42880/50000 (95%)]\tLoss: 1.507631\n",
      "Train Epoch: 1 [43520/50000 (97%)]\tLoss: 1.694373\n",
      "Train Epoch: 1 [44160/50000 (98%)]\tLoss: 1.722200\n",
      "Train Epoch: 1 [44800/50000 (99%)]\tLoss: 1.449034\n",
      "\n",
      "Test set: Average loss: 0.1629, Accuracy: 1936/50000 (4%)\n",
      "\n",
      "Train Epoch: 2 [00000/50000 (00%)]\tLoss: 1.732033\n",
      "Train Epoch: 2 [00640/50000 (01%)]\tLoss: 1.525266\n",
      "Train Epoch: 2 [01280/50000 (03%)]\tLoss: 1.637155\n",
      "Train Epoch: 2 [01920/50000 (04%)]\tLoss: 1.547379\n",
      "Train Epoch: 2 [02560/50000 (06%)]\tLoss: 1.575614\n",
      "Train Epoch: 2 [03200/50000 (07%)]\tLoss: 1.373550\n",
      "Train Epoch: 2 [03840/50000 (09%)]\tLoss: 1.803075\n",
      "Train Epoch: 2 [04480/50000 (10%)]\tLoss: 1.502070\n",
      "Train Epoch: 2 [05120/50000 (11%)]\tLoss: 1.581093\n",
      "Train Epoch: 2 [05760/50000 (13%)]\tLoss: 1.841668\n",
      "Train Epoch: 2 [06400/50000 (14%)]\tLoss: 1.558143\n",
      "Train Epoch: 2 [07040/50000 (16%)]\tLoss: 1.488039\n",
      "Train Epoch: 2 [07680/50000 (17%)]\tLoss: 1.492364\n",
      "Train Epoch: 2 [08320/50000 (18%)]\tLoss: 1.654656\n",
      "Train Epoch: 2 [08960/50000 (20%)]\tLoss: 1.465809\n",
      "Train Epoch: 2 [09600/50000 (21%)]\tLoss: 1.725123\n",
      "Train Epoch: 2 [10240/50000 (23%)]\tLoss: 1.756411\n",
      "Train Epoch: 2 [10880/50000 (24%)]\tLoss: 1.433827\n",
      "Train Epoch: 2 [11520/50000 (26%)]\tLoss: 1.751342\n",
      "Train Epoch: 2 [12160/50000 (27%)]\tLoss: 1.410206\n",
      "Train Epoch: 2 [12800/50000 (28%)]\tLoss: 1.667419\n",
      "Train Epoch: 2 [13440/50000 (30%)]\tLoss: 1.704668\n",
      "Train Epoch: 2 [14080/50000 (31%)]\tLoss: 1.834843\n",
      "Train Epoch: 2 [14720/50000 (33%)]\tLoss: 1.876948\n",
      "Train Epoch: 2 [15360/50000 (34%)]\tLoss: 1.665566\n",
      "Train Epoch: 2 [16000/50000 (36%)]\tLoss: 1.503576\n",
      "Train Epoch: 2 [16640/50000 (37%)]\tLoss: 1.446923\n",
      "Train Epoch: 2 [17280/50000 (38%)]\tLoss: 1.555558\n",
      "Train Epoch: 2 [17920/50000 (40%)]\tLoss: 1.537970\n",
      "Train Epoch: 2 [18560/50000 (41%)]\tLoss: 1.756276\n",
      "Train Epoch: 2 [19200/50000 (43%)]\tLoss: 1.624868\n",
      "Train Epoch: 2 [19840/50000 (44%)]\tLoss: 1.400460\n",
      "Train Epoch: 2 [20480/50000 (45%)]\tLoss: 1.784117\n",
      "Train Epoch: 2 [21120/50000 (47%)]\tLoss: 1.649466\n",
      "Train Epoch: 2 [21760/50000 (48%)]\tLoss: 1.533443\n",
      "Train Epoch: 2 [22400/50000 (50%)]\tLoss: 1.425302\n",
      "Train Epoch: 2 [23040/50000 (51%)]\tLoss: 1.429525\n",
      "Train Epoch: 2 [23680/50000 (53%)]\tLoss: 1.553396\n",
      "Train Epoch: 2 [24320/50000 (54%)]\tLoss: 1.415728\n",
      "Train Epoch: 2 [24960/50000 (55%)]\tLoss: 1.409095\n",
      "Train Epoch: 2 [25600/50000 (57%)]\tLoss: 1.823424\n",
      "Train Epoch: 2 [26240/50000 (58%)]\tLoss: 1.456980\n",
      "Train Epoch: 2 [26880/50000 (60%)]\tLoss: 1.555073\n",
      "Train Epoch: 2 [27520/50000 (61%)]\tLoss: 1.401801\n",
      "Train Epoch: 2 [28160/50000 (62%)]\tLoss: 1.847008\n",
      "Train Epoch: 2 [28800/50000 (64%)]\tLoss: 1.462233\n",
      "Train Epoch: 2 [29440/50000 (65%)]\tLoss: 1.378086\n",
      "Train Epoch: 2 [30080/50000 (67%)]\tLoss: 1.554226\n",
      "Train Epoch: 2 [30720/50000 (68%)]\tLoss: 1.476229\n",
      "Train Epoch: 2 [31360/50000 (70%)]\tLoss: 1.401524\n",
      "Train Epoch: 2 [32000/50000 (71%)]\tLoss: 1.277094\n",
      "Train Epoch: 2 [32640/50000 (72%)]\tLoss: 1.437166\n",
      "Train Epoch: 2 [33280/50000 (74%)]\tLoss: 1.392965\n",
      "Train Epoch: 2 [33920/50000 (75%)]\tLoss: 1.531176\n",
      "Train Epoch: 2 [34560/50000 (77%)]\tLoss: 1.484705\n",
      "Train Epoch: 2 [35200/50000 (78%)]\tLoss: 1.613531\n",
      "Train Epoch: 2 [35840/50000 (80%)]\tLoss: 1.300529\n",
      "Train Epoch: 2 [36480/50000 (81%)]\tLoss: 1.472483\n",
      "Train Epoch: 2 [37120/50000 (82%)]\tLoss: 1.417350\n",
      "Train Epoch: 2 [37760/50000 (84%)]\tLoss: 1.420123\n",
      "Train Epoch: 2 [38400/50000 (85%)]\tLoss: 1.570238\n",
      "Train Epoch: 2 [39040/50000 (87%)]\tLoss: 1.529682\n",
      "Train Epoch: 2 [39680/50000 (88%)]\tLoss: 1.495791\n",
      "Train Epoch: 2 [40320/50000 (89%)]\tLoss: 1.460388\n",
      "Train Epoch: 2 [40960/50000 (91%)]\tLoss: 1.461300\n",
      "Train Epoch: 2 [41600/50000 (92%)]\tLoss: 1.412562\n",
      "Train Epoch: 2 [42240/50000 (94%)]\tLoss: 1.783491\n",
      "Train Epoch: 2 [42880/50000 (95%)]\tLoss: 1.428344\n",
      "Train Epoch: 2 [43520/50000 (97%)]\tLoss: 1.340814\n",
      "Train Epoch: 2 [44160/50000 (98%)]\tLoss: 1.702407\n",
      "Train Epoch: 2 [44800/50000 (99%)]\tLoss: 1.606572\n",
      "\n",
      "Test set: Average loss: 0.1451, Accuracy: 2316/50000 (5%)\n",
      "\n",
      "Train Epoch: 3 [00000/50000 (00%)]\tLoss: 1.542482\n",
      "Train Epoch: 3 [00640/50000 (01%)]\tLoss: 1.414715\n",
      "Train Epoch: 3 [01280/50000 (03%)]\tLoss: 1.612708\n",
      "Train Epoch: 3 [01920/50000 (04%)]\tLoss: 1.463053\n",
      "Train Epoch: 3 [02560/50000 (06%)]\tLoss: 1.580637\n",
      "Train Epoch: 3 [03200/50000 (07%)]\tLoss: 1.412047\n",
      "Train Epoch: 3 [03840/50000 (09%)]\tLoss: 1.489095\n",
      "Train Epoch: 3 [04480/50000 (10%)]\tLoss: 1.546962\n",
      "Train Epoch: 3 [05120/50000 (11%)]\tLoss: 1.499918\n",
      "Train Epoch: 3 [05760/50000 (13%)]\tLoss: 1.617778\n",
      "Train Epoch: 3 [06400/50000 (14%)]\tLoss: 1.529329\n",
      "Train Epoch: 3 [07040/50000 (16%)]\tLoss: 1.332199\n",
      "Train Epoch: 3 [07680/50000 (17%)]\tLoss: 1.518220\n",
      "Train Epoch: 3 [08320/50000 (18%)]\tLoss: 1.348192\n",
      "Train Epoch: 3 [08960/50000 (20%)]\tLoss: 1.292194\n",
      "Train Epoch: 3 [09600/50000 (21%)]\tLoss: 1.511541\n",
      "Train Epoch: 3 [10240/50000 (23%)]\tLoss: 1.368900\n",
      "Train Epoch: 3 [10880/50000 (24%)]\tLoss: 1.353764\n",
      "Train Epoch: 3 [11520/50000 (26%)]\tLoss: 1.449600\n",
      "Train Epoch: 3 [12160/50000 (27%)]\tLoss: 1.394927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [12800/50000 (28%)]\tLoss: 1.478503\n",
      "Train Epoch: 3 [13440/50000 (30%)]\tLoss: 1.377202\n",
      "Train Epoch: 3 [14080/50000 (31%)]\tLoss: 1.411937\n",
      "Train Epoch: 3 [14720/50000 (33%)]\tLoss: 1.270038\n",
      "Train Epoch: 3 [15360/50000 (34%)]\tLoss: 1.447731\n",
      "Train Epoch: 3 [16000/50000 (36%)]\tLoss: 1.282784\n",
      "Train Epoch: 3 [16640/50000 (37%)]\tLoss: 1.241104\n",
      "Train Epoch: 3 [17280/50000 (38%)]\tLoss: 1.344651\n",
      "Train Epoch: 3 [17920/50000 (40%)]\tLoss: 1.042982\n",
      "Train Epoch: 3 [18560/50000 (41%)]\tLoss: 1.555338\n",
      "Train Epoch: 3 [19200/50000 (43%)]\tLoss: 1.370060\n",
      "Train Epoch: 3 [19840/50000 (44%)]\tLoss: 1.501180\n",
      "Train Epoch: 3 [20480/50000 (45%)]\tLoss: 1.276277\n",
      "Train Epoch: 3 [21120/50000 (47%)]\tLoss: 1.517687\n",
      "Train Epoch: 3 [21760/50000 (48%)]\tLoss: 1.341361\n",
      "Train Epoch: 3 [22400/50000 (50%)]\tLoss: 1.449593\n",
      "Train Epoch: 3 [23040/50000 (51%)]\tLoss: 1.416455\n",
      "Train Epoch: 3 [23680/50000 (53%)]\tLoss: 1.258052\n",
      "Train Epoch: 3 [24320/50000 (54%)]\tLoss: 1.319130\n",
      "Train Epoch: 3 [24960/50000 (55%)]\tLoss: 1.248134\n",
      "Train Epoch: 3 [25600/50000 (57%)]\tLoss: 1.362628\n",
      "Train Epoch: 3 [26240/50000 (58%)]\tLoss: 0.994867\n",
      "Train Epoch: 3 [26880/50000 (60%)]\tLoss: 1.413252\n",
      "Train Epoch: 3 [27520/50000 (61%)]\tLoss: 1.441184\n",
      "Train Epoch: 3 [28160/50000 (62%)]\tLoss: 1.386660\n",
      "Train Epoch: 3 [28800/50000 (64%)]\tLoss: 1.295786\n",
      "Train Epoch: 3 [29440/50000 (65%)]\tLoss: 1.379690\n",
      "Train Epoch: 3 [30080/50000 (67%)]\tLoss: 1.191766\n",
      "Train Epoch: 3 [30720/50000 (68%)]\tLoss: 1.617329\n",
      "Train Epoch: 3 [31360/50000 (70%)]\tLoss: 1.317582\n",
      "Train Epoch: 3 [32000/50000 (71%)]\tLoss: 1.385074\n",
      "Train Epoch: 3 [32640/50000 (72%)]\tLoss: 1.254008\n",
      "Train Epoch: 3 [33280/50000 (74%)]\tLoss: 1.286824\n",
      "Train Epoch: 3 [33920/50000 (75%)]\tLoss: 1.351556\n",
      "Train Epoch: 3 [34560/50000 (77%)]\tLoss: 1.582967\n",
      "Train Epoch: 3 [35200/50000 (78%)]\tLoss: 1.556163\n",
      "Train Epoch: 3 [35840/50000 (80%)]\tLoss: 1.575137\n",
      "Train Epoch: 3 [36480/50000 (81%)]\tLoss: 1.482853\n",
      "Train Epoch: 3 [37120/50000 (82%)]\tLoss: 1.541681\n",
      "Train Epoch: 3 [37760/50000 (84%)]\tLoss: 1.370352\n",
      "Train Epoch: 3 [38400/50000 (85%)]\tLoss: 1.309139\n",
      "Train Epoch: 3 [39040/50000 (87%)]\tLoss: 1.282691\n",
      "Train Epoch: 3 [39680/50000 (88%)]\tLoss: 1.480125\n",
      "Train Epoch: 3 [40320/50000 (89%)]\tLoss: 1.403839\n",
      "Train Epoch: 3 [40960/50000 (91%)]\tLoss: 1.405435\n",
      "Train Epoch: 3 [41600/50000 (92%)]\tLoss: 1.298085\n",
      "Train Epoch: 3 [42240/50000 (94%)]\tLoss: 1.232296\n",
      "Train Epoch: 3 [42880/50000 (95%)]\tLoss: 1.540714\n",
      "Train Epoch: 3 [43520/50000 (97%)]\tLoss: 1.260109\n",
      "Train Epoch: 3 [44160/50000 (98%)]\tLoss: 1.342057\n",
      "Train Epoch: 3 [44800/50000 (99%)]\tLoss: 1.307511\n",
      "\n",
      "Test set: Average loss: 0.1359, Accuracy: 2439/50000 (5%)\n",
      "\n",
      "Train Epoch: 4 [00000/50000 (00%)]\tLoss: 1.343612\n",
      "Train Epoch: 4 [00640/50000 (01%)]\tLoss: 1.130881\n",
      "Train Epoch: 4 [01280/50000 (03%)]\tLoss: 1.333855\n",
      "Train Epoch: 4 [01920/50000 (04%)]\tLoss: 1.304106\n",
      "Train Epoch: 4 [02560/50000 (06%)]\tLoss: 1.287004\n",
      "Train Epoch: 4 [03200/50000 (07%)]\tLoss: 1.197658\n",
      "Train Epoch: 4 [03840/50000 (09%)]\tLoss: 1.478891\n",
      "Train Epoch: 4 [04480/50000 (10%)]\tLoss: 1.202520\n",
      "Train Epoch: 4 [05120/50000 (11%)]\tLoss: 1.332835\n",
      "Train Epoch: 4 [05760/50000 (13%)]\tLoss: 1.374184\n",
      "Train Epoch: 4 [06400/50000 (14%)]\tLoss: 1.462536\n",
      "Train Epoch: 4 [07040/50000 (16%)]\tLoss: 1.372796\n",
      "Train Epoch: 4 [07680/50000 (17%)]\tLoss: 1.386701\n",
      "Train Epoch: 4 [08320/50000 (18%)]\tLoss: 1.351406\n",
      "Train Epoch: 4 [08960/50000 (20%)]\tLoss: 1.297299\n",
      "Train Epoch: 4 [09600/50000 (21%)]\tLoss: 1.353462\n",
      "Train Epoch: 4 [10240/50000 (23%)]\tLoss: 1.165020\n",
      "Train Epoch: 4 [10880/50000 (24%)]\tLoss: 1.202221\n",
      "Train Epoch: 4 [11520/50000 (26%)]\tLoss: 1.479115\n",
      "Train Epoch: 4 [12160/50000 (27%)]\tLoss: 1.373190\n",
      "Train Epoch: 4 [12800/50000 (28%)]\tLoss: 1.313268\n",
      "Train Epoch: 4 [13440/50000 (30%)]\tLoss: 1.439185\n",
      "Train Epoch: 4 [14080/50000 (31%)]\tLoss: 1.316028\n",
      "Train Epoch: 4 [14720/50000 (33%)]\tLoss: 1.504117\n",
      "Train Epoch: 4 [15360/50000 (34%)]\tLoss: 1.287353\n",
      "Train Epoch: 4 [16000/50000 (36%)]\tLoss: 1.073217\n",
      "Train Epoch: 4 [16640/50000 (37%)]\tLoss: 1.168305\n",
      "Train Epoch: 4 [17280/50000 (38%)]\tLoss: 1.097066\n",
      "Train Epoch: 4 [17920/50000 (40%)]\tLoss: 1.266701\n",
      "Train Epoch: 4 [18560/50000 (41%)]\tLoss: 1.343324\n",
      "Train Epoch: 4 [19200/50000 (43%)]\tLoss: 1.044599\n",
      "Train Epoch: 4 [19840/50000 (44%)]\tLoss: 1.194862\n",
      "Train Epoch: 4 [20480/50000 (45%)]\tLoss: 1.159779\n",
      "Train Epoch: 4 [21120/50000 (47%)]\tLoss: 1.188092\n",
      "Train Epoch: 4 [21760/50000 (48%)]\tLoss: 1.100622\n",
      "Train Epoch: 4 [22400/50000 (50%)]\tLoss: 1.259232\n",
      "Train Epoch: 4 [23040/50000 (51%)]\tLoss: 1.229448\n",
      "Train Epoch: 4 [23680/50000 (53%)]\tLoss: 1.543687\n",
      "Train Epoch: 4 [24320/50000 (54%)]\tLoss: 1.324119\n",
      "Train Epoch: 4 [24960/50000 (55%)]\tLoss: 1.219186\n",
      "Train Epoch: 4 [25600/50000 (57%)]\tLoss: 1.381496\n",
      "Train Epoch: 4 [26240/50000 (58%)]\tLoss: 1.393522\n",
      "Train Epoch: 4 [26880/50000 (60%)]\tLoss: 1.383272\n",
      "Train Epoch: 4 [27520/50000 (61%)]\tLoss: 1.144884\n",
      "Train Epoch: 4 [28160/50000 (62%)]\tLoss: 1.176086\n",
      "Train Epoch: 4 [28800/50000 (64%)]\tLoss: 1.394454\n",
      "Train Epoch: 4 [29440/50000 (65%)]\tLoss: 1.391880\n",
      "Train Epoch: 4 [30080/50000 (67%)]\tLoss: 1.258319\n",
      "Train Epoch: 4 [30720/50000 (68%)]\tLoss: 1.441940\n",
      "Train Epoch: 4 [31360/50000 (70%)]\tLoss: 1.527259\n",
      "Train Epoch: 4 [32000/50000 (71%)]\tLoss: 1.299298\n",
      "Train Epoch: 4 [32640/50000 (72%)]\tLoss: 1.080410\n",
      "Train Epoch: 4 [33280/50000 (74%)]\tLoss: 1.301416\n",
      "Train Epoch: 4 [33920/50000 (75%)]\tLoss: 1.403786\n",
      "Train Epoch: 4 [34560/50000 (77%)]\tLoss: 1.388614\n",
      "Train Epoch: 4 [35200/50000 (78%)]\tLoss: 1.322465\n",
      "Train Epoch: 4 [35840/50000 (80%)]\tLoss: 1.511198\n",
      "Train Epoch: 4 [36480/50000 (81%)]\tLoss: 1.424800\n",
      "Train Epoch: 4 [37120/50000 (82%)]\tLoss: 1.456578\n",
      "Train Epoch: 4 [37760/50000 (84%)]\tLoss: 1.215173\n",
      "Train Epoch: 4 [38400/50000 (85%)]\tLoss: 1.498508\n",
      "Train Epoch: 4 [39040/50000 (87%)]\tLoss: 1.325708\n",
      "Train Epoch: 4 [39680/50000 (88%)]\tLoss: 1.395326\n",
      "Train Epoch: 4 [40320/50000 (89%)]\tLoss: 1.278345\n",
      "Train Epoch: 4 [40960/50000 (91%)]\tLoss: 1.129475\n",
      "Train Epoch: 4 [41600/50000 (92%)]\tLoss: 1.463002\n",
      "Train Epoch: 4 [42240/50000 (94%)]\tLoss: 1.039863\n",
      "Train Epoch: 4 [42880/50000 (95%)]\tLoss: 1.433871\n",
      "Train Epoch: 4 [43520/50000 (97%)]\tLoss: 1.467494\n",
      "Train Epoch: 4 [44160/50000 (98%)]\tLoss: 1.238849\n",
      "Train Epoch: 4 [44800/50000 (99%)]\tLoss: 1.247033\n",
      "\n",
      "Test set: Average loss: 0.1297, Accuracy: 2653/50000 (5%)\n",
      "\n",
      "Train Epoch: 5 [00000/50000 (00%)]\tLoss: 1.161667\n",
      "Train Epoch: 5 [00640/50000 (01%)]\tLoss: 1.108117\n",
      "Train Epoch: 5 [01280/50000 (03%)]\tLoss: 1.039961\n",
      "Train Epoch: 5 [01920/50000 (04%)]\tLoss: 1.192510\n",
      "Train Epoch: 5 [02560/50000 (06%)]\tLoss: 1.176429\n",
      "Train Epoch: 5 [03200/50000 (07%)]\tLoss: 1.449849\n",
      "Train Epoch: 5 [03840/50000 (09%)]\tLoss: 1.114523\n",
      "Train Epoch: 5 [04480/50000 (10%)]\tLoss: 1.183439\n",
      "Train Epoch: 5 [05120/50000 (11%)]\tLoss: 1.204674\n",
      "Train Epoch: 5 [05760/50000 (13%)]\tLoss: 1.246577\n",
      "Train Epoch: 5 [06400/50000 (14%)]\tLoss: 1.240872\n",
      "Train Epoch: 5 [07040/50000 (16%)]\tLoss: 1.344873\n",
      "Train Epoch: 5 [07680/50000 (17%)]\tLoss: 1.254069\n",
      "Train Epoch: 5 [08320/50000 (18%)]\tLoss: 1.153564\n",
      "Train Epoch: 5 [08960/50000 (20%)]\tLoss: 1.275369\n",
      "Train Epoch: 5 [09600/50000 (21%)]\tLoss: 1.211081\n",
      "Train Epoch: 5 [10240/50000 (23%)]\tLoss: 1.263039\n",
      "Train Epoch: 5 [10880/50000 (24%)]\tLoss: 1.368909\n",
      "Train Epoch: 5 [11520/50000 (26%)]\tLoss: 1.194177\n",
      "Train Epoch: 5 [12160/50000 (27%)]\tLoss: 1.306564\n",
      "Train Epoch: 5 [12800/50000 (28%)]\tLoss: 1.166435\n",
      "Train Epoch: 5 [13440/50000 (30%)]\tLoss: 1.298729\n",
      "Train Epoch: 5 [14080/50000 (31%)]\tLoss: 1.239815\n",
      "Train Epoch: 5 [14720/50000 (33%)]\tLoss: 1.303280\n",
      "Train Epoch: 5 [15360/50000 (34%)]\tLoss: 1.124517\n",
      "Train Epoch: 5 [16000/50000 (36%)]\tLoss: 1.365530\n",
      "Train Epoch: 5 [16640/50000 (37%)]\tLoss: 1.115226\n",
      "Train Epoch: 5 [17280/50000 (38%)]\tLoss: 1.432364\n",
      "Train Epoch: 5 [17920/50000 (40%)]\tLoss: 1.211420\n",
      "Train Epoch: 5 [18560/50000 (41%)]\tLoss: 1.522253\n",
      "Train Epoch: 5 [19200/50000 (43%)]\tLoss: 1.327120\n",
      "Train Epoch: 5 [19840/50000 (44%)]\tLoss: 1.204424\n",
      "Train Epoch: 5 [20480/50000 (45%)]\tLoss: 1.233743\n",
      "Train Epoch: 5 [21120/50000 (47%)]\tLoss: 0.961869\n",
      "Train Epoch: 5 [21760/50000 (48%)]\tLoss: 1.486913\n",
      "Train Epoch: 5 [22400/50000 (50%)]\tLoss: 1.040577\n",
      "Train Epoch: 5 [23040/50000 (51%)]\tLoss: 1.114250\n",
      "Train Epoch: 5 [23680/50000 (53%)]\tLoss: 1.126603\n",
      "Train Epoch: 5 [24320/50000 (54%)]\tLoss: 1.378190\n",
      "Train Epoch: 5 [24960/50000 (55%)]\tLoss: 1.081879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [25600/50000 (57%)]\tLoss: 1.501039\n",
      "Train Epoch: 5 [26240/50000 (58%)]\tLoss: 1.026789\n",
      "Train Epoch: 5 [26880/50000 (60%)]\tLoss: 1.110331\n",
      "Train Epoch: 5 [27520/50000 (61%)]\tLoss: 1.239107\n",
      "Train Epoch: 5 [28160/50000 (62%)]\tLoss: 1.145940\n",
      "Train Epoch: 5 [28800/50000 (64%)]\tLoss: 1.434730\n",
      "Train Epoch: 5 [29440/50000 (65%)]\tLoss: 1.069602\n",
      "Train Epoch: 5 [30080/50000 (67%)]\tLoss: 1.149599\n",
      "Train Epoch: 5 [30720/50000 (68%)]\tLoss: 1.311656\n",
      "Train Epoch: 5 [31360/50000 (70%)]\tLoss: 1.117375\n",
      "Train Epoch: 5 [32000/50000 (71%)]\tLoss: 1.156481\n",
      "Train Epoch: 5 [32640/50000 (72%)]\tLoss: 1.059829\n",
      "Train Epoch: 5 [33280/50000 (74%)]\tLoss: 1.118913\n",
      "Train Epoch: 5 [33920/50000 (75%)]\tLoss: 1.134185\n",
      "Train Epoch: 5 [34560/50000 (77%)]\tLoss: 1.308957\n",
      "Train Epoch: 5 [35200/50000 (78%)]\tLoss: 1.174639\n",
      "Train Epoch: 5 [35840/50000 (80%)]\tLoss: 1.171293\n",
      "Train Epoch: 5 [36480/50000 (81%)]\tLoss: 0.947902\n",
      "Train Epoch: 5 [37120/50000 (82%)]\tLoss: 1.066269\n",
      "Train Epoch: 5 [37760/50000 (84%)]\tLoss: 1.106371\n",
      "Train Epoch: 5 [38400/50000 (85%)]\tLoss: 1.355446\n",
      "Train Epoch: 5 [39040/50000 (87%)]\tLoss: 1.094944\n",
      "Train Epoch: 5 [39680/50000 (88%)]\tLoss: 1.060579\n",
      "Train Epoch: 5 [40320/50000 (89%)]\tLoss: 1.079107\n",
      "Train Epoch: 5 [40960/50000 (91%)]\tLoss: 1.220962\n",
      "Train Epoch: 5 [41600/50000 (92%)]\tLoss: 1.210838\n",
      "Train Epoch: 5 [42240/50000 (94%)]\tLoss: 1.036130\n",
      "Train Epoch: 5 [42880/50000 (95%)]\tLoss: 1.235722\n",
      "Train Epoch: 5 [43520/50000 (97%)]\tLoss: 1.133209\n",
      "Train Epoch: 5 [44160/50000 (98%)]\tLoss: 1.326965\n",
      "Train Epoch: 5 [44800/50000 (99%)]\tLoss: 0.956298\n",
      "\n",
      "Test set: Average loss: 0.1237, Accuracy: 2719/50000 (5%)\n",
      "\n",
      "Train Epoch: 6 [00000/50000 (00%)]\tLoss: 1.068332\n",
      "Train Epoch: 6 [00640/50000 (01%)]\tLoss: 1.100168\n",
      "Train Epoch: 6 [01280/50000 (03%)]\tLoss: 1.281142\n",
      "Train Epoch: 6 [01920/50000 (04%)]\tLoss: 1.118827\n",
      "Train Epoch: 6 [02560/50000 (06%)]\tLoss: 1.059292\n",
      "Train Epoch: 6 [03200/50000 (07%)]\tLoss: 1.098436\n",
      "Train Epoch: 6 [03840/50000 (09%)]\tLoss: 1.330522\n",
      "Train Epoch: 6 [04480/50000 (10%)]\tLoss: 1.107830\n",
      "Train Epoch: 6 [05120/50000 (11%)]\tLoss: 1.138809\n",
      "Train Epoch: 6 [05760/50000 (13%)]\tLoss: 1.111245\n",
      "Train Epoch: 6 [06400/50000 (14%)]\tLoss: 1.168737\n",
      "Train Epoch: 6 [07040/50000 (16%)]\tLoss: 1.104719\n",
      "Train Epoch: 6 [07680/50000 (17%)]\tLoss: 1.065905\n",
      "Train Epoch: 6 [08320/50000 (18%)]\tLoss: 1.187811\n",
      "Train Epoch: 6 [08960/50000 (20%)]\tLoss: 1.202788\n",
      "Train Epoch: 6 [09600/50000 (21%)]\tLoss: 1.325700\n",
      "Train Epoch: 6 [10240/50000 (23%)]\tLoss: 1.105377\n",
      "Train Epoch: 6 [10880/50000 (24%)]\tLoss: 1.031758\n",
      "Train Epoch: 6 [11520/50000 (26%)]\tLoss: 1.312582\n",
      "Train Epoch: 6 [12160/50000 (27%)]\tLoss: 1.144250\n",
      "Train Epoch: 6 [12800/50000 (28%)]\tLoss: 1.276048\n",
      "Train Epoch: 6 [13440/50000 (30%)]\tLoss: 1.309837\n",
      "Train Epoch: 6 [14080/50000 (31%)]\tLoss: 1.106744\n",
      "Train Epoch: 6 [14720/50000 (33%)]\tLoss: 1.173864\n",
      "Train Epoch: 6 [15360/50000 (34%)]\tLoss: 1.079778\n",
      "Train Epoch: 6 [16000/50000 (36%)]\tLoss: 1.256464\n",
      "Train Epoch: 6 [16640/50000 (37%)]\tLoss: 1.308696\n",
      "Train Epoch: 6 [17280/50000 (38%)]\tLoss: 1.301871\n",
      "Train Epoch: 6 [17920/50000 (40%)]\tLoss: 1.288396\n",
      "Train Epoch: 6 [18560/50000 (41%)]\tLoss: 1.223210\n",
      "Train Epoch: 6 [19200/50000 (43%)]\tLoss: 1.435131\n",
      "Train Epoch: 6 [19840/50000 (44%)]\tLoss: 0.984121\n",
      "Train Epoch: 6 [20480/50000 (45%)]\tLoss: 1.294350\n",
      "Train Epoch: 6 [21120/50000 (47%)]\tLoss: 1.219944\n",
      "Train Epoch: 6 [21760/50000 (48%)]\tLoss: 1.284467\n",
      "Train Epoch: 6 [22400/50000 (50%)]\tLoss: 1.128661\n",
      "Train Epoch: 6 [23040/50000 (51%)]\tLoss: 1.200363\n",
      "Train Epoch: 6 [23680/50000 (53%)]\tLoss: 1.686353\n",
      "Train Epoch: 6 [24320/50000 (54%)]\tLoss: 1.018107\n",
      "Train Epoch: 6 [24960/50000 (55%)]\tLoss: 1.419534\n",
      "Train Epoch: 6 [25600/50000 (57%)]\tLoss: 1.288000\n",
      "Train Epoch: 6 [26240/50000 (58%)]\tLoss: 1.169838\n",
      "Train Epoch: 6 [26880/50000 (60%)]\tLoss: 1.222256\n",
      "Train Epoch: 6 [27520/50000 (61%)]\tLoss: 1.144145\n",
      "Train Epoch: 6 [28160/50000 (62%)]\tLoss: 1.305483\n",
      "Train Epoch: 6 [28800/50000 (64%)]\tLoss: 1.039229\n",
      "Train Epoch: 6 [29440/50000 (65%)]\tLoss: 1.176433\n",
      "Train Epoch: 6 [30080/50000 (67%)]\tLoss: 1.072460\n",
      "Train Epoch: 6 [30720/50000 (68%)]\tLoss: 1.383731\n",
      "Train Epoch: 6 [31360/50000 (70%)]\tLoss: 1.206238\n",
      "Train Epoch: 6 [32000/50000 (71%)]\tLoss: 1.174920\n",
      "Train Epoch: 6 [32640/50000 (72%)]\tLoss: 1.294744\n",
      "Train Epoch: 6 [33280/50000 (74%)]\tLoss: 1.250137\n",
      "Train Epoch: 6 [33920/50000 (75%)]\tLoss: 1.156167\n",
      "Train Epoch: 6 [34560/50000 (77%)]\tLoss: 0.992262\n",
      "Train Epoch: 6 [35200/50000 (78%)]\tLoss: 1.177467\n",
      "Train Epoch: 6 [35840/50000 (80%)]\tLoss: 1.166559\n",
      "Train Epoch: 6 [36480/50000 (81%)]\tLoss: 1.361986\n",
      "Train Epoch: 6 [37120/50000 (82%)]\tLoss: 1.199273\n",
      "Train Epoch: 6 [37760/50000 (84%)]\tLoss: 1.251615\n",
      "Train Epoch: 6 [38400/50000 (85%)]\tLoss: 1.141855\n",
      "Train Epoch: 6 [39040/50000 (87%)]\tLoss: 1.187088\n",
      "Train Epoch: 6 [39680/50000 (88%)]\tLoss: 1.313404\n",
      "Train Epoch: 6 [40320/50000 (89%)]\tLoss: 1.172209\n",
      "Train Epoch: 6 [40960/50000 (91%)]\tLoss: 0.864385\n",
      "Train Epoch: 6 [41600/50000 (92%)]\tLoss: 1.064540\n",
      "Train Epoch: 6 [42240/50000 (94%)]\tLoss: 1.078005\n",
      "Train Epoch: 6 [42880/50000 (95%)]\tLoss: 1.199527\n",
      "Train Epoch: 6 [43520/50000 (97%)]\tLoss: 0.938572\n",
      "Train Epoch: 6 [44160/50000 (98%)]\tLoss: 1.479854\n",
      "Train Epoch: 6 [44800/50000 (99%)]\tLoss: 1.248907\n",
      "\n",
      "Test set: Average loss: 0.1171, Accuracy: 2803/50000 (6%)\n",
      "\n",
      "Train Epoch: 7 [00000/50000 (00%)]\tLoss: 1.177224\n",
      "Train Epoch: 7 [00640/50000 (01%)]\tLoss: 1.075383\n",
      "Train Epoch: 7 [01280/50000 (03%)]\tLoss: 1.241686\n",
      "Train Epoch: 7 [01920/50000 (04%)]\tLoss: 1.193436\n",
      "Train Epoch: 7 [02560/50000 (06%)]\tLoss: 1.298404\n",
      "Train Epoch: 7 [03200/50000 (07%)]\tLoss: 1.293096\n",
      "Train Epoch: 7 [03840/50000 (09%)]\tLoss: 1.128987\n",
      "Train Epoch: 7 [04480/50000 (10%)]\tLoss: 1.025970\n",
      "Train Epoch: 7 [05120/50000 (11%)]\tLoss: 1.071943\n",
      "Train Epoch: 7 [05760/50000 (13%)]\tLoss: 1.064031\n",
      "Train Epoch: 7 [06400/50000 (14%)]\tLoss: 1.078426\n",
      "Train Epoch: 7 [07040/50000 (16%)]\tLoss: 0.975271\n",
      "Train Epoch: 7 [07680/50000 (17%)]\tLoss: 1.058154\n",
      "Train Epoch: 7 [08320/50000 (18%)]\tLoss: 1.266173\n",
      "Train Epoch: 7 [08960/50000 (20%)]\tLoss: 1.106709\n",
      "Train Epoch: 7 [09600/50000 (21%)]\tLoss: 0.920885\n",
      "Train Epoch: 7 [10240/50000 (23%)]\tLoss: 1.166774\n",
      "Train Epoch: 7 [10880/50000 (24%)]\tLoss: 1.178178\n",
      "Train Epoch: 7 [11520/50000 (26%)]\tLoss: 1.267831\n",
      "Train Epoch: 7 [12160/50000 (27%)]\tLoss: 1.157464\n",
      "Train Epoch: 7 [12800/50000 (28%)]\tLoss: 1.137012\n",
      "Train Epoch: 7 [13440/50000 (30%)]\tLoss: 1.248876\n",
      "Train Epoch: 7 [14080/50000 (31%)]\tLoss: 1.255042\n",
      "Train Epoch: 7 [14720/50000 (33%)]\tLoss: 1.259243\n",
      "Train Epoch: 7 [15360/50000 (34%)]\tLoss: 1.018023\n",
      "Train Epoch: 7 [16000/50000 (36%)]\tLoss: 0.977220\n",
      "Train Epoch: 7 [16640/50000 (37%)]\tLoss: 1.085796\n",
      "Train Epoch: 7 [17280/50000 (38%)]\tLoss: 1.039598\n",
      "Train Epoch: 7 [17920/50000 (40%)]\tLoss: 1.209021\n",
      "Train Epoch: 7 [18560/50000 (41%)]\tLoss: 1.101268\n",
      "Train Epoch: 7 [19200/50000 (43%)]\tLoss: 1.046663\n",
      "Train Epoch: 7 [19840/50000 (44%)]\tLoss: 1.380902\n",
      "Train Epoch: 7 [20480/50000 (45%)]\tLoss: 1.353113\n",
      "Train Epoch: 7 [21120/50000 (47%)]\tLoss: 1.169304\n",
      "Train Epoch: 7 [21760/50000 (48%)]\tLoss: 1.027383\n",
      "Train Epoch: 7 [22400/50000 (50%)]\tLoss: 1.448188\n",
      "Train Epoch: 7 [23040/50000 (51%)]\tLoss: 1.023471\n",
      "Train Epoch: 7 [23680/50000 (53%)]\tLoss: 0.960331\n",
      "Train Epoch: 7 [24320/50000 (54%)]\tLoss: 1.278888\n",
      "Train Epoch: 7 [24960/50000 (55%)]\tLoss: 1.061402\n",
      "Train Epoch: 7 [25600/50000 (57%)]\tLoss: 0.969355\n",
      "Train Epoch: 7 [26240/50000 (58%)]\tLoss: 1.167930\n",
      "Train Epoch: 7 [26880/50000 (60%)]\tLoss: 1.036669\n",
      "Train Epoch: 7 [27520/50000 (61%)]\tLoss: 0.888585\n",
      "Train Epoch: 7 [28160/50000 (62%)]\tLoss: 1.114048\n",
      "Train Epoch: 7 [28800/50000 (64%)]\tLoss: 1.044252\n",
      "Train Epoch: 7 [29440/50000 (65%)]\tLoss: 1.101412\n",
      "Train Epoch: 7 [30080/50000 (67%)]\tLoss: 1.029955\n",
      "Train Epoch: 7 [30720/50000 (68%)]\tLoss: 1.058542\n",
      "Train Epoch: 7 [31360/50000 (70%)]\tLoss: 0.829720\n",
      "Train Epoch: 7 [32000/50000 (71%)]\tLoss: 0.928274\n",
      "Train Epoch: 7 [32640/50000 (72%)]\tLoss: 0.923905\n",
      "Train Epoch: 7 [33280/50000 (74%)]\tLoss: 1.033603\n",
      "Train Epoch: 7 [33920/50000 (75%)]\tLoss: 1.109063\n",
      "Train Epoch: 7 [34560/50000 (77%)]\tLoss: 1.094384\n",
      "Train Epoch: 7 [35200/50000 (78%)]\tLoss: 0.808956\n",
      "Train Epoch: 7 [35840/50000 (80%)]\tLoss: 0.934662\n",
      "Train Epoch: 7 [36480/50000 (81%)]\tLoss: 1.213047\n",
      "Train Epoch: 7 [37120/50000 (82%)]\tLoss: 1.084730\n",
      "Train Epoch: 7 [37760/50000 (84%)]\tLoss: 1.094692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [38400/50000 (85%)]\tLoss: 1.099205\n",
      "Train Epoch: 7 [39040/50000 (87%)]\tLoss: 1.056570\n",
      "Train Epoch: 7 [39680/50000 (88%)]\tLoss: 1.197369\n",
      "Train Epoch: 7 [40320/50000 (89%)]\tLoss: 1.144065\n",
      "Train Epoch: 7 [40960/50000 (91%)]\tLoss: 0.963556\n",
      "Train Epoch: 7 [41600/50000 (92%)]\tLoss: 1.010987\n",
      "Train Epoch: 7 [42240/50000 (94%)]\tLoss: 1.080479\n",
      "Train Epoch: 7 [42880/50000 (95%)]\tLoss: 1.172958\n",
      "Train Epoch: 7 [43520/50000 (97%)]\tLoss: 1.151149\n",
      "Train Epoch: 7 [44160/50000 (98%)]\tLoss: 1.065286\n",
      "Train Epoch: 7 [44800/50000 (99%)]\tLoss: 1.302160\n",
      "\n",
      "Test set: Average loss: 0.1150, Accuracy: 2887/50000 (6%)\n",
      "\n",
      "Train Epoch: 8 [00000/50000 (00%)]\tLoss: 1.180228\n",
      "Train Epoch: 8 [00640/50000 (01%)]\tLoss: 0.937151\n",
      "Train Epoch: 8 [01280/50000 (03%)]\tLoss: 1.175508\n",
      "Train Epoch: 8 [01920/50000 (04%)]\tLoss: 1.134860\n",
      "Train Epoch: 8 [02560/50000 (06%)]\tLoss: 1.118706\n",
      "Train Epoch: 8 [03200/50000 (07%)]\tLoss: 1.074574\n",
      "Train Epoch: 8 [03840/50000 (09%)]\tLoss: 0.964571\n",
      "Train Epoch: 8 [04480/50000 (10%)]\tLoss: 1.025298\n",
      "Train Epoch: 8 [05120/50000 (11%)]\tLoss: 0.849121\n",
      "Train Epoch: 8 [05760/50000 (13%)]\tLoss: 1.219378\n",
      "Train Epoch: 8 [06400/50000 (14%)]\tLoss: 0.887449\n",
      "Train Epoch: 8 [07040/50000 (16%)]\tLoss: 1.015992\n",
      "Train Epoch: 8 [07680/50000 (17%)]\tLoss: 1.103426\n",
      "Train Epoch: 8 [08320/50000 (18%)]\tLoss: 1.166446\n",
      "Train Epoch: 8 [08960/50000 (20%)]\tLoss: 1.105475\n",
      "Train Epoch: 8 [09600/50000 (21%)]\tLoss: 1.061193\n",
      "Train Epoch: 8 [10240/50000 (23%)]\tLoss: 1.137350\n",
      "Train Epoch: 8 [10880/50000 (24%)]\tLoss: 1.047925\n",
      "Train Epoch: 8 [11520/50000 (26%)]\tLoss: 1.155282\n",
      "Train Epoch: 8 [12160/50000 (27%)]\tLoss: 1.215351\n",
      "Train Epoch: 8 [12800/50000 (28%)]\tLoss: 0.819407\n",
      "Train Epoch: 8 [13440/50000 (30%)]\tLoss: 1.006052\n",
      "Train Epoch: 8 [14080/50000 (31%)]\tLoss: 1.044653\n",
      "Train Epoch: 8 [14720/50000 (33%)]\tLoss: 1.114350\n",
      "Train Epoch: 8 [15360/50000 (34%)]\tLoss: 0.838764\n",
      "Train Epoch: 8 [16000/50000 (36%)]\tLoss: 1.195045\n",
      "Train Epoch: 8 [16640/50000 (37%)]\tLoss: 0.972882\n",
      "Train Epoch: 8 [17280/50000 (38%)]\tLoss: 1.095924\n",
      "Train Epoch: 8 [17920/50000 (40%)]\tLoss: 0.942076\n",
      "Train Epoch: 8 [18560/50000 (41%)]\tLoss: 0.947391\n",
      "Train Epoch: 8 [19200/50000 (43%)]\tLoss: 1.400088\n",
      "Train Epoch: 8 [19840/50000 (44%)]\tLoss: 1.037974\n",
      "Train Epoch: 8 [20480/50000 (45%)]\tLoss: 1.045148\n",
      "Train Epoch: 8 [21120/50000 (47%)]\tLoss: 0.770186\n",
      "Train Epoch: 8 [21760/50000 (48%)]\tLoss: 0.980391\n",
      "Train Epoch: 8 [22400/50000 (50%)]\tLoss: 1.175556\n",
      "Train Epoch: 8 [23040/50000 (51%)]\tLoss: 1.119915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6560760f7325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# save the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a7d002381dc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/william-oBc2a6gD/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "    \n",
    "    # save the model!\n",
    "    # source for timestamp formatting: https://stackoverflow.com/q/10607688/781938\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # source for f-string: https://stackoverflow.com/a/42562236/781938\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        f'{timestamp}-cifar10_mobilenet-{epoch:05d}.pytorchmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(optimizer, torch.optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(type(optimizer), torch.optim.Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
